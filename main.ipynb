{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rXMXfciUOMN"
      },
      "source": [
        "Importing Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WYM8KOr-TUqc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style=\"white\")\n",
        "import math\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import scale\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.regularizers import l1,l2,l1_l2\n",
        "import tensorflow as tf\n",
        "\n",
        "seed = 7\n",
        "np.random.seed(seed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TliCGx4UcnV"
      },
      "source": [
        "Reading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZmA7Lc7UU3J",
        "outputId": "35a8e9fc-fd8b-4f85-cbd2-f762d6618d09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('diabetes.csv')\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "ApSo4ZlMUhOM",
        "outputId": "e5d31260-ff61-4115-eb4a-355b09d9e7c3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dtypes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Pregnancies</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Glucose</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BloodPressure</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SkinThickness</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Insulin</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BMI</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Outcome</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           dtypes\n",
              "Pregnancies                 int64\n",
              "Glucose                     int64\n",
              "BloodPressure               int64\n",
              "SkinThickness               int64\n",
              "Insulin                     int64\n",
              "BMI                       float64\n",
              "DiabetesPedigreeFunction  float64\n",
              "Age                         int64\n",
              "Outcome                     int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(df.dtypes).rename(columns = {0 : 'dtypes'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6DAM0h9Utps"
      },
      "source": [
        "Separating Target Variable from rest of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "Nn6-yN2BUoqi",
        "outputId": "871ec72c-ab6c-443e-fc1b-fe6c3194c8d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      1\n",
              "1      0\n",
              "2      1\n",
              "3      0\n",
              "4      1\n",
              "      ..\n",
              "763    0\n",
              "764    0\n",
              "765    0\n",
              "766    1\n",
              "767    0\n",
              "Name: Outcome, Length: 768, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "outcome = df.loc[:,\"Outcome\"]\n",
        "display(outcome)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaCfm2F7VI96"
      },
      "source": [
        "Converting Dependent Variables from Dataframe to Numpy Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7pE4yLU8U2FI"
      },
      "outputs": [],
      "source": [
        "df_X = df.drop(\"Outcome\", axis = 1)\n",
        "dataset_X = df_X.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euXx879UVdcv",
        "outputId": "42abcd1b-5ae8-4946-c2c1-5f9c65584384"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "768\n",
            "8\n"
          ]
        }
      ],
      "source": [
        "print(len(dataset_X))\n",
        "print(len(dataset_X[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCUaZEmkWXwL"
      },
      "source": [
        "**Start of Logistic Regression Part**.\n",
        "Scaling the Dataset so that Training becomes easier "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zS4udO0YVukk",
        "outputId": "15bc3d9f-dfab-4ebf-bd03-273be7a7021b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(768, 8)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_X = scale(dataset_X)\n",
        "dataset_X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF92fz7mW1Jk"
      },
      "source": [
        "Splitting the Dataset into Training Testing and Validation sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xO4HDumNWpwL",
        "outputId": "c4be8123-c448-4bfb-fef7-bc9b81767ec6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-1.14185152 -0.09059057  0.77001375  1.66000666  1.30417549  1.75242756\n",
            "   0.23896296 -0.19067191]\n",
            " [-0.54791859  2.38188392  0.04624525  4.92186584 -0.69289057  0.34362394\n",
            "   0.31144581  2.44704844]\n",
            " [ 0.04601433  0.34756947 -3.57259724 -1.28821221 -0.69289057  0.1151693\n",
            "  -0.51304659 -0.87137393]\n",
            " [-0.54791859 -0.49745345 -0.57412775  1.22091023  0.12330164  0.36900779\n",
            "  -0.74559573 -0.70119842]\n",
            " [ 1.23388019  2.10020961  0.45982725 -1.28821221 -0.69289057  2.01895798\n",
            "  -1.01136617  0.83038113]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(460, 8)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(dataset_X, outcome.values, test_size=0.2, random_state = 5)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)\n",
        "\n",
        "b = np.ones((460,1))\n",
        "\n",
        "print(X_train[:5])\n",
        "\n",
        "X_train = np.asmatrix(X_train)\n",
        "y_train = np.asmatrix(y_train).T\n",
        "X_test = np.asmatrix(X_test)\n",
        "y_test = np.asmatrix(y_test).T\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRv7F7n9XgQH"
      },
      "source": [
        "Initializing the parameters like number of epochs, learning rate etc. before starting training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ly95kdBXGOG",
        "outputId": "b5d3d5c9-3f9a-4b6c-db9e-7b13a89a0755"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8, 1)\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 10000\n",
        "wT = np.ones((8,1))\n",
        "lr = 1e-6\n",
        "n_features = 8\n",
        "n_samples = 460\n",
        "w = np.ones((8,1))\n",
        "y_actual = np.zeros((460,1))\n",
        "print(wT.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ex8RQqYXqrI"
      },
      "source": [
        "Training the Logistic Regression Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Txc0WnHLXngQ"
      },
      "outputs": [],
      "source": [
        "for k in range(n_epochs): #epoch_loop\n",
        "\n",
        "  z = np.dot(X_train,wT)\n",
        "  y_actual = 1.0 / (1 + np.exp(-z))\n",
        "  dz = np.dot(X_train.T,(y_actual - y_train))\n",
        "  w = w - lr * dz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwVah6gNX19w"
      },
      "source": [
        "Weights Matrix After Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP7d4fMtXx0O",
        "outputId": "c5c587a4-fa71-4853-db1f-c0e4d6c2affe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.79506345]\n",
            " [0.98679884]\n",
            " [0.27464648]\n",
            " [0.23137957]\n",
            " [0.40050611]\n",
            " [0.67285176]\n",
            " [0.74494953]\n",
            " [0.70650555]]\n"
          ]
        }
      ],
      "source": [
        "print(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9F2xDu0YCdF"
      },
      "source": [
        "Evaluating the Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8Lh551hX8m8",
        "outputId": "951d8dbc-3584-4777-8189-96744f7a8632"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "104.0\n",
            "0.6753246753246753\n"
          ]
        }
      ],
      "source": [
        "val = np.dot(X_val,w)\n",
        "val = 1.0 / (1 + np.exp(-val))\n",
        "for i in range(len(val)):\n",
        "  if(val[i]>=0.5):\n",
        "    val[i] = 1.0\n",
        "  else:\n",
        "    val[i] = 0.0\n",
        "\n",
        "val_count = 0.0\n",
        "for i in range(len(val)):\n",
        "  if(val[i]==y_val[i]):\n",
        "    val_count = val_count + 1\n",
        "print(val_count)\n",
        "val_accuracy = val_count/len(y_val)\n",
        "print(val_accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm8KerqPYTMJ"
      },
      "source": [
        "Predicting the Test Data using the Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urUhzLE0YLsv",
        "outputId": "171e71ba-b084-4ef1-832f-0abe5a7a2793"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.43531909]\n",
            " [0.77865324]\n",
            " [0.06333239]\n",
            " [0.20419314]\n",
            " [0.05926849]\n",
            " [0.24438617]\n",
            " [0.73644904]\n",
            " [0.85934647]\n",
            " [0.8649624 ]\n",
            " [0.90574092]\n",
            " [0.06265199]\n",
            " [0.64373378]\n",
            " [0.99169323]\n",
            " [0.50043734]\n",
            " [0.05089346]\n",
            " [0.15015774]\n",
            " [0.05959612]\n",
            " [0.96279542]\n",
            " [0.68325897]\n",
            " [0.029348  ]\n",
            " [0.26853802]\n",
            " [0.70379746]\n",
            " [0.08255347]\n",
            " [0.91335134]\n",
            " [0.00472434]\n",
            " [0.48725683]\n",
            " [0.57851447]\n",
            " [0.73074254]\n",
            " [0.13662954]\n",
            " [0.94782815]\n",
            " [0.05296518]\n",
            " [0.3240652 ]\n",
            " [0.58010495]\n",
            " [0.25419596]\n",
            " [0.88929427]\n",
            " [0.18995352]\n",
            " [0.55751906]\n",
            " [0.87781736]\n",
            " [0.05685123]\n",
            " [0.01311804]\n",
            " [0.56593273]\n",
            " [0.72879249]\n",
            " [0.62835753]\n",
            " [0.98840172]\n",
            " [0.28512908]\n",
            " [0.99952865]\n",
            " [0.98097399]\n",
            " [0.05307418]\n",
            " [0.81982468]\n",
            " [0.55715891]\n",
            " [0.85158077]\n",
            " [0.21068201]\n",
            " [0.96319236]\n",
            " [0.75679276]\n",
            " [0.29465722]\n",
            " [0.57713246]\n",
            " [0.52209705]\n",
            " [0.26618226]\n",
            " [0.25018789]\n",
            " [0.04492138]\n",
            " [0.88683146]\n",
            " [0.89220626]\n",
            " [0.94367601]\n",
            " [0.01927291]\n",
            " [0.53398747]\n",
            " [0.06665475]\n",
            " [0.40862408]\n",
            " [0.72410419]\n",
            " [0.8293205 ]\n",
            " [0.26970419]\n",
            " [0.9842442 ]\n",
            " [0.37326867]\n",
            " [0.22924862]\n",
            " [0.98419471]\n",
            " [0.99919911]\n",
            " [0.29893716]\n",
            " [0.10078765]\n",
            " [0.77419047]\n",
            " [0.93202807]\n",
            " [0.03932097]\n",
            " [0.94689492]\n",
            " [0.99927432]\n",
            " [0.74873435]\n",
            " [0.98265104]\n",
            " [0.15108324]\n",
            " [0.2601377 ]\n",
            " [0.07172262]\n",
            " [0.85467432]\n",
            " [0.17714206]\n",
            " [0.69142593]\n",
            " [0.99723834]\n",
            " [0.19509162]\n",
            " [0.46416095]\n",
            " [0.18747926]\n",
            " [0.24152211]\n",
            " [0.40533066]\n",
            " [0.41879092]\n",
            " [0.44251479]\n",
            " [0.31165615]\n",
            " [0.10778897]\n",
            " [0.03324882]\n",
            " [0.11178777]\n",
            " [0.6722651 ]\n",
            " [0.99794209]\n",
            " [0.08748162]\n",
            " [0.97792656]\n",
            " [0.6009795 ]\n",
            " [0.02491086]\n",
            " [0.99236713]\n",
            " [0.3262398 ]\n",
            " [0.13387233]\n",
            " [0.93709377]\n",
            " [0.10814017]\n",
            " [0.4590926 ]\n",
            " [0.10746077]\n",
            " [0.06075807]\n",
            " [0.91631316]\n",
            " [0.97922165]\n",
            " [0.16544836]\n",
            " [0.03963729]\n",
            " [0.95014464]\n",
            " [0.95504415]\n",
            " [0.11798363]\n",
            " [0.23445925]\n",
            " [0.6887885 ]\n",
            " [0.16472901]\n",
            " [0.08029031]\n",
            " [0.10023343]\n",
            " [0.06783112]\n",
            " [0.03836729]\n",
            " [0.94334166]\n",
            " [0.51107822]\n",
            " [0.88406003]\n",
            " [0.38677421]\n",
            " [0.3114115 ]\n",
            " [0.21153194]\n",
            " [0.81221835]\n",
            " [0.08952578]\n",
            " [0.97328623]\n",
            " [0.0763527 ]\n",
            " [0.28657822]\n",
            " [0.98811421]\n",
            " [0.14172388]\n",
            " [0.9528518 ]\n",
            " [0.04183246]\n",
            " [0.5475642 ]\n",
            " [0.70666476]\n",
            " [0.66395249]\n",
            " [0.58428561]\n",
            " [0.05762853]\n",
            " [0.8886675 ]\n",
            " [0.2653677 ]\n",
            " [0.09096878]\n",
            " [0.70439389]]\n"
          ]
        }
      ],
      "source": [
        "predict = np.dot(X_test,w)\n",
        "predict = 1.0 / (1 + np.exp(-predict))\n",
        "print(predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGRWNKLzY3vF",
        "outputId": "ff18416f-a8c2-4ffc-b7ee-6ae321ef41b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]]\n",
            "(154, 1)\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(predict)):\n",
        "  if(predict[i]>=0.5):\n",
        "    predict[i] = 1.0\n",
        "  else:\n",
        "    predict[i] = 0.0\n",
        "\n",
        "print(predict)\n",
        "print(predict.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SL5HS5-ZHke"
      },
      "source": [
        "Evaluating the Predicted Accuracy on the Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKuQAcO6Ydfk",
        "outputId": "401223af-aeb0-4939-ebef-1a70f3133b1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "116.0\n",
            "0.7532467532467533\n"
          ]
        }
      ],
      "source": [
        "count = 0.0\n",
        "for i in range(len(predict)):\n",
        "  if(predict[i]==y_test[i]):\n",
        "    count = count + 1\n",
        "print(count)\n",
        "accuracy = count/len(y_test)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0nkS6CpZaIl"
      },
      "source": [
        "Calculating different Evaluation Metrics like Precision, Recall, F1 Score etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtQYaCEdZWCM",
        "outputId": "1633e8dc-4cc9-4756-d54c-4e1bc1fb0e4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.753247\n",
            "Precision: 0.608108\n",
            "Recall: 0.833333\n",
            "f1_Score: 0.703125\n",
            "Cohen's Kappa: 0.500683\n",
            "ROC AUC Score: 0.771667\n",
            "Confusion Matrix:\n",
            "[[71 29]\n",
            " [ 9 45]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(\"Accuracy: %f\" % accuracy)\n",
        "\n",
        "precision = precision_score(y_test, predict)\n",
        "print(\"Precision: %f\" % precision)\n",
        "\n",
        "recall = recall_score(y_test, predict)\n",
        "print(\"Recall: %f\" % recall)\n",
        "\n",
        "f1 = f1_score(y_test, predict)\n",
        "print(\"f1_Score: %f\" % f1)\n",
        "\n",
        "kappa = cohen_kappa_score(y_test, predict)\n",
        "print(\"Cohen's Kappa: %f\" % kappa)\n",
        "\n",
        "auc = roc_auc_score(y_test, predict)\n",
        "print(\"ROC AUC Score: %f\" % auc)\n",
        "\n",
        "matrix = confusion_matrix(y_test, predict)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lztM_BFXaMF3"
      },
      "source": [
        "**Start of Neural Networks.** Scaling the model using Standard Scaler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "voPGoHATZpmd"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "dataset_X = scaler.fit_transform(dataset_X)\n",
        "#print(dataset_train[:,5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY-o3bsoaY39"
      },
      "source": [
        "Splitting the Dataset into Training Testing and Validation in the ratio 60:20:20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0purzBGaPOE"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(dataset_X, outcome.values, test_size=0.2, random_state = 5)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)\n",
        "\n",
        "#print(X_train[:5])\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_val.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmT_KKaDaquI"
      },
      "source": [
        "Defining the model with three hidden layers with 40,25 and 15 neurons respectively and with l2 regularization of 0.2. In the hidden layers we have taken activation function as \"RelU\". The input diamension is equal to the number of features, 8. The output layer has \"sigmoid\" activation function. The model is trained with Adam optimizer with a learning rate of 1e-5 and binary-crossentropy loss for 500 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlm-LATFakE3",
        "outputId": "0b2e4779-298e-41c5-df3f-de5bb3c5633e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 40)                360       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 25)                1025      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 15)                390       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 16        \n",
            "=================================================================\n",
            "Total params: 1,791\n",
            "Trainable params: 1,791\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# model.add(Dense(1000, input_dim=8, init='uniform', activation='relu'))\n",
        "\n",
        "model.add(Dense(40, activation='relu', input_dim=8, kernel_regularizer = l2(l=0.1)))\n",
        "model.add(Dense(25, activation='relu'))\n",
        "model.add(Dense(15, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer=Adam(learning_rate= 0.00001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtWMxpifbCNW"
      },
      "source": [
        "Training the Neural Network Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsKToTNWa6mT",
        "outputId": "629e0da9-6722-4f95-ebeb-39de490b2446"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "58/58 [==============================] - 1s 5ms/step - loss: 2.1264 - accuracy: 0.3826 - val_loss: 2.1173 - val_accuracy: 0.3701\n",
            "Epoch 2/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 2.1190 - accuracy: 0.3913 - val_loss: 2.1102 - val_accuracy: 0.3766\n",
            "Epoch 3/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 2.1116 - accuracy: 0.3957 - val_loss: 2.1030 - val_accuracy: 0.3896\n",
            "Epoch 4/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 2.1042 - accuracy: 0.3978 - val_loss: 2.0959 - val_accuracy: 0.3896\n",
            "Epoch 5/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 2.0969 - accuracy: 0.4152 - val_loss: 2.0888 - val_accuracy: 0.3961\n",
            "Epoch 6/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 2.0897 - accuracy: 0.4239 - val_loss: 2.0818 - val_accuracy: 0.4026\n",
            "Epoch 7/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 2.0825 - accuracy: 0.4304 - val_loss: 2.0747 - val_accuracy: 0.4091\n",
            "Epoch 8/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 2.0753 - accuracy: 0.4348 - val_loss: 2.0678 - val_accuracy: 0.4351\n",
            "Epoch 9/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 2.0682 - accuracy: 0.4413 - val_loss: 2.0609 - val_accuracy: 0.4416\n",
            "Epoch 10/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 2.0611 - accuracy: 0.4370 - val_loss: 2.0539 - val_accuracy: 0.4610\n",
            "Epoch 11/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 2.0541 - accuracy: 0.4543 - val_loss: 2.0471 - val_accuracy: 0.4675\n",
            "Epoch 12/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 2.0471 - accuracy: 0.4587 - val_loss: 2.0403 - val_accuracy: 0.4805\n",
            "Epoch 13/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 2.0402 - accuracy: 0.4630 - val_loss: 2.0335 - val_accuracy: 0.4675\n",
            "Epoch 14/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 2.0333 - accuracy: 0.4739 - val_loss: 2.0268 - val_accuracy: 0.4740\n",
            "Epoch 15/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 2.0264 - accuracy: 0.4826 - val_loss: 2.0201 - val_accuracy: 0.4870\n",
            "Epoch 16/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 2.0196 - accuracy: 0.4891 - val_loss: 2.0134 - val_accuracy: 0.4935\n",
            "Epoch 17/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 2.0128 - accuracy: 0.4957 - val_loss: 2.0068 - val_accuracy: 0.5065\n",
            "Epoch 18/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 2.0060 - accuracy: 0.5000 - val_loss: 2.0002 - val_accuracy: 0.5065\n",
            "Epoch 19/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.9993 - accuracy: 0.5109 - val_loss: 1.9937 - val_accuracy: 0.5130\n",
            "Epoch 20/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.9926 - accuracy: 0.5217 - val_loss: 1.9872 - val_accuracy: 0.5260\n",
            "Epoch 21/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.9859 - accuracy: 0.5261 - val_loss: 1.9807 - val_accuracy: 0.5325\n",
            "Epoch 22/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 1.9793 - accuracy: 0.5283 - val_loss: 1.9742 - val_accuracy: 0.5390\n",
            "Epoch 23/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.9728 - accuracy: 0.5348 - val_loss: 1.9678 - val_accuracy: 0.5455\n",
            "Epoch 24/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.9662 - accuracy: 0.5522 - val_loss: 1.9614 - val_accuracy: 0.5519\n",
            "Epoch 25/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.9597 - accuracy: 0.5630 - val_loss: 1.9551 - val_accuracy: 0.5519\n",
            "Epoch 26/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.9532 - accuracy: 0.5674 - val_loss: 1.9487 - val_accuracy: 0.5519\n",
            "Epoch 27/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.9468 - accuracy: 0.5696 - val_loss: 1.9424 - val_accuracy: 0.5519\n",
            "Epoch 28/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.9404 - accuracy: 0.5739 - val_loss: 1.9362 - val_accuracy: 0.5714\n",
            "Epoch 29/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.9340 - accuracy: 0.5783 - val_loss: 1.9300 - val_accuracy: 0.5779\n",
            "Epoch 30/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.9277 - accuracy: 0.5891 - val_loss: 1.9238 - val_accuracy: 0.5974\n",
            "Epoch 31/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.9214 - accuracy: 0.5891 - val_loss: 1.9176 - val_accuracy: 0.5974\n",
            "Epoch 32/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 1.9151 - accuracy: 0.5935 - val_loss: 1.9115 - val_accuracy: 0.5974\n",
            "Epoch 33/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 1.9089 - accuracy: 0.5935 - val_loss: 1.9054 - val_accuracy: 0.5974\n",
            "Epoch 34/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.9027 - accuracy: 0.5957 - val_loss: 1.8993 - val_accuracy: 0.6039\n",
            "Epoch 35/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.8965 - accuracy: 0.6000 - val_loss: 1.8932 - val_accuracy: 0.5974\n",
            "Epoch 36/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.8903 - accuracy: 0.6043 - val_loss: 1.8872 - val_accuracy: 0.6104\n",
            "Epoch 37/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.8842 - accuracy: 0.6043 - val_loss: 1.8812 - val_accuracy: 0.6234\n",
            "Epoch 38/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.8781 - accuracy: 0.6087 - val_loss: 1.8752 - val_accuracy: 0.6169\n",
            "Epoch 39/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.8720 - accuracy: 0.6152 - val_loss: 1.8693 - val_accuracy: 0.6299\n",
            "Epoch 40/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.8659 - accuracy: 0.6174 - val_loss: 1.8633 - val_accuracy: 0.6299\n",
            "Epoch 41/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.8599 - accuracy: 0.6217 - val_loss: 1.8575 - val_accuracy: 0.6299\n",
            "Epoch 42/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.8539 - accuracy: 0.6283 - val_loss: 1.8516 - val_accuracy: 0.6299\n",
            "Epoch 43/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.8478 - accuracy: 0.6413 - val_loss: 1.8457 - val_accuracy: 0.6299\n",
            "Epoch 44/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.8419 - accuracy: 0.6435 - val_loss: 1.8398 - val_accuracy: 0.6364\n",
            "Epoch 45/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 1.8359 - accuracy: 0.6457 - val_loss: 1.8341 - val_accuracy: 0.6364\n",
            "Epoch 46/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.8300 - accuracy: 0.6457 - val_loss: 1.8283 - val_accuracy: 0.6429\n",
            "Epoch 47/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.8240 - accuracy: 0.6457 - val_loss: 1.8225 - val_accuracy: 0.6429\n",
            "Epoch 48/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.8181 - accuracy: 0.6457 - val_loss: 1.8167 - val_accuracy: 0.6429\n",
            "Epoch 49/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.8123 - accuracy: 0.6500 - val_loss: 1.8110 - val_accuracy: 0.6494\n",
            "Epoch 50/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.8064 - accuracy: 0.6522 - val_loss: 1.8053 - val_accuracy: 0.6494\n",
            "Epoch 51/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.8006 - accuracy: 0.6565 - val_loss: 1.7996 - val_accuracy: 0.6494\n",
            "Epoch 52/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.7948 - accuracy: 0.6565 - val_loss: 1.7939 - val_accuracy: 0.6494\n",
            "Epoch 53/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.7890 - accuracy: 0.6587 - val_loss: 1.7882 - val_accuracy: 0.6429\n",
            "Epoch 54/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.7832 - accuracy: 0.6587 - val_loss: 1.7826 - val_accuracy: 0.6429\n",
            "Epoch 55/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.7774 - accuracy: 0.6587 - val_loss: 1.7770 - val_accuracy: 0.6429\n",
            "Epoch 56/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.7717 - accuracy: 0.6630 - val_loss: 1.7714 - val_accuracy: 0.6429\n",
            "Epoch 57/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.7660 - accuracy: 0.6609 - val_loss: 1.7658 - val_accuracy: 0.6429\n",
            "Epoch 58/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.7603 - accuracy: 0.6630 - val_loss: 1.7603 - val_accuracy: 0.6429\n",
            "Epoch 59/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.7546 - accuracy: 0.6630 - val_loss: 1.7547 - val_accuracy: 0.6429\n",
            "Epoch 60/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.7490 - accuracy: 0.6652 - val_loss: 1.7492 - val_accuracy: 0.6429\n",
            "Epoch 61/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.7433 - accuracy: 0.6652 - val_loss: 1.7437 - val_accuracy: 0.6429\n",
            "Epoch 62/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.7377 - accuracy: 0.6674 - val_loss: 1.7382 - val_accuracy: 0.6429\n",
            "Epoch 63/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.7321 - accuracy: 0.6674 - val_loss: 1.7328 - val_accuracy: 0.6429\n",
            "Epoch 64/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.7266 - accuracy: 0.6674 - val_loss: 1.7274 - val_accuracy: 0.6429\n",
            "Epoch 65/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.7210 - accuracy: 0.6674 - val_loss: 1.7219 - val_accuracy: 0.6429\n",
            "Epoch 66/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.7155 - accuracy: 0.6674 - val_loss: 1.7165 - val_accuracy: 0.6429\n",
            "Epoch 67/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.7100 - accuracy: 0.6674 - val_loss: 1.7112 - val_accuracy: 0.6429\n",
            "Epoch 68/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.7045 - accuracy: 0.6674 - val_loss: 1.7058 - val_accuracy: 0.6429\n",
            "Epoch 69/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.6990 - accuracy: 0.6674 - val_loss: 1.7005 - val_accuracy: 0.6429\n",
            "Epoch 70/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.6936 - accuracy: 0.6674 - val_loss: 1.6952 - val_accuracy: 0.6429\n",
            "Epoch 71/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.6882 - accuracy: 0.6674 - val_loss: 1.6899 - val_accuracy: 0.6429\n",
            "Epoch 72/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.6828 - accuracy: 0.6674 - val_loss: 1.6846 - val_accuracy: 0.6429\n",
            "Epoch 73/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.6774 - accuracy: 0.6674 - val_loss: 1.6793 - val_accuracy: 0.6429\n",
            "Epoch 74/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.6720 - accuracy: 0.6674 - val_loss: 1.6741 - val_accuracy: 0.6429\n",
            "Epoch 75/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.6667 - accuracy: 0.6674 - val_loss: 1.6689 - val_accuracy: 0.6429\n",
            "Epoch 76/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.6613 - accuracy: 0.6674 - val_loss: 1.6637 - val_accuracy: 0.6429\n",
            "Epoch 77/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.6560 - accuracy: 0.6674 - val_loss: 1.6585 - val_accuracy: 0.6429\n",
            "Epoch 78/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.6507 - accuracy: 0.6652 - val_loss: 1.6533 - val_accuracy: 0.6429\n",
            "Epoch 79/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.6454 - accuracy: 0.6652 - val_loss: 1.6481 - val_accuracy: 0.6429\n",
            "Epoch 80/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.6402 - accuracy: 0.6652 - val_loss: 1.6430 - val_accuracy: 0.6429\n",
            "Epoch 81/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.6349 - accuracy: 0.6652 - val_loss: 1.6379 - val_accuracy: 0.6429\n",
            "Epoch 82/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.6297 - accuracy: 0.6652 - val_loss: 1.6328 - val_accuracy: 0.6429\n",
            "Epoch 83/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.6245 - accuracy: 0.6652 - val_loss: 1.6277 - val_accuracy: 0.6429\n",
            "Epoch 84/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.6194 - accuracy: 0.6652 - val_loss: 1.6227 - val_accuracy: 0.6429\n",
            "Epoch 85/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.6142 - accuracy: 0.6652 - val_loss: 1.6176 - val_accuracy: 0.6429\n",
            "Epoch 86/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.6090 - accuracy: 0.6652 - val_loss: 1.6126 - val_accuracy: 0.6429\n",
            "Epoch 87/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.6039 - accuracy: 0.6630 - val_loss: 1.6076 - val_accuracy: 0.6429\n",
            "Epoch 88/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.5988 - accuracy: 0.6609 - val_loss: 1.6025 - val_accuracy: 0.6429\n",
            "Epoch 89/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.5937 - accuracy: 0.6609 - val_loss: 1.5976 - val_accuracy: 0.6429\n",
            "Epoch 90/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.5886 - accuracy: 0.6609 - val_loss: 1.5926 - val_accuracy: 0.6429\n",
            "Epoch 91/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.5835 - accuracy: 0.6609 - val_loss: 1.5876 - val_accuracy: 0.6429\n",
            "Epoch 92/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.5785 - accuracy: 0.6609 - val_loss: 1.5827 - val_accuracy: 0.6429\n",
            "Epoch 93/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.5734 - accuracy: 0.6609 - val_loss: 1.5778 - val_accuracy: 0.6429\n",
            "Epoch 94/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.5684 - accuracy: 0.6609 - val_loss: 1.5729 - val_accuracy: 0.6429\n",
            "Epoch 95/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.5634 - accuracy: 0.6652 - val_loss: 1.5680 - val_accuracy: 0.6429\n",
            "Epoch 96/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.5585 - accuracy: 0.6652 - val_loss: 1.5631 - val_accuracy: 0.6429\n",
            "Epoch 97/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.5535 - accuracy: 0.6630 - val_loss: 1.5582 - val_accuracy: 0.6429\n",
            "Epoch 98/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.5485 - accuracy: 0.6630 - val_loss: 1.5534 - val_accuracy: 0.6429\n",
            "Epoch 99/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.5436 - accuracy: 0.6630 - val_loss: 1.5486 - val_accuracy: 0.6429\n",
            "Epoch 100/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.5387 - accuracy: 0.6630 - val_loss: 1.5437 - val_accuracy: 0.6429\n",
            "Epoch 101/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.5337 - accuracy: 0.6630 - val_loss: 1.5389 - val_accuracy: 0.6429\n",
            "Epoch 102/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.5288 - accuracy: 0.6652 - val_loss: 1.5342 - val_accuracy: 0.6429\n",
            "Epoch 103/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.5240 - accuracy: 0.6652 - val_loss: 1.5294 - val_accuracy: 0.6429\n",
            "Epoch 104/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.5191 - accuracy: 0.6652 - val_loss: 1.5246 - val_accuracy: 0.6429\n",
            "Epoch 105/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.5143 - accuracy: 0.6652 - val_loss: 1.5198 - val_accuracy: 0.6429\n",
            "Epoch 106/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.5094 - accuracy: 0.6652 - val_loss: 1.5151 - val_accuracy: 0.6429\n",
            "Epoch 107/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.5046 - accuracy: 0.6652 - val_loss: 1.5104 - val_accuracy: 0.6429\n",
            "Epoch 108/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.4998 - accuracy: 0.6652 - val_loss: 1.5057 - val_accuracy: 0.6429\n",
            "Epoch 109/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.4950 - accuracy: 0.6652 - val_loss: 1.5010 - val_accuracy: 0.6429\n",
            "Epoch 110/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.4903 - accuracy: 0.6652 - val_loss: 1.4963 - val_accuracy: 0.6429\n",
            "Epoch 111/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.4855 - accuracy: 0.6652 - val_loss: 1.4917 - val_accuracy: 0.6429\n",
            "Epoch 112/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.4808 - accuracy: 0.6652 - val_loss: 1.4870 - val_accuracy: 0.6429\n",
            "Epoch 113/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.4761 - accuracy: 0.6652 - val_loss: 1.4824 - val_accuracy: 0.6429\n",
            "Epoch 114/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.4714 - accuracy: 0.6652 - val_loss: 1.4777 - val_accuracy: 0.6429\n",
            "Epoch 115/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.4666 - accuracy: 0.6652 - val_loss: 1.4731 - val_accuracy: 0.6429\n",
            "Epoch 116/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.4620 - accuracy: 0.6652 - val_loss: 1.4685 - val_accuracy: 0.6429\n",
            "Epoch 117/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.4573 - accuracy: 0.6652 - val_loss: 1.4639 - val_accuracy: 0.6429\n",
            "Epoch 118/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.4526 - accuracy: 0.6652 - val_loss: 1.4594 - val_accuracy: 0.6429\n",
            "Epoch 119/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.4480 - accuracy: 0.6652 - val_loss: 1.4548 - val_accuracy: 0.6429\n",
            "Epoch 120/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.4434 - accuracy: 0.6674 - val_loss: 1.4503 - val_accuracy: 0.6429\n",
            "Epoch 121/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.4388 - accuracy: 0.6674 - val_loss: 1.4458 - val_accuracy: 0.6429\n",
            "Epoch 122/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.4342 - accuracy: 0.6674 - val_loss: 1.4412 - val_accuracy: 0.6429\n",
            "Epoch 123/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.4296 - accuracy: 0.6674 - val_loss: 1.4367 - val_accuracy: 0.6429\n",
            "Epoch 124/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.4251 - accuracy: 0.6652 - val_loss: 1.4322 - val_accuracy: 0.6429\n",
            "Epoch 125/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.4205 - accuracy: 0.6652 - val_loss: 1.4277 - val_accuracy: 0.6429\n",
            "Epoch 126/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.4160 - accuracy: 0.6652 - val_loss: 1.4233 - val_accuracy: 0.6429\n",
            "Epoch 127/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.4115 - accuracy: 0.6652 - val_loss: 1.4188 - val_accuracy: 0.6429\n",
            "Epoch 128/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.4070 - accuracy: 0.6652 - val_loss: 1.4144 - val_accuracy: 0.6429\n",
            "Epoch 129/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.4026 - accuracy: 0.6652 - val_loss: 1.4100 - val_accuracy: 0.6429\n",
            "Epoch 130/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.3981 - accuracy: 0.6652 - val_loss: 1.4056 - val_accuracy: 0.6429\n",
            "Epoch 131/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.3936 - accuracy: 0.6652 - val_loss: 1.4012 - val_accuracy: 0.6429\n",
            "Epoch 132/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.3892 - accuracy: 0.6652 - val_loss: 1.3968 - val_accuracy: 0.6429\n",
            "Epoch 133/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.3848 - accuracy: 0.6652 - val_loss: 1.3925 - val_accuracy: 0.6429\n",
            "Epoch 134/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.3804 - accuracy: 0.6652 - val_loss: 1.3882 - val_accuracy: 0.6429\n",
            "Epoch 135/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.3761 - accuracy: 0.6652 - val_loss: 1.3838 - val_accuracy: 0.6429\n",
            "Epoch 136/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.3717 - accuracy: 0.6652 - val_loss: 1.3795 - val_accuracy: 0.6429\n",
            "Epoch 137/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.3674 - accuracy: 0.6652 - val_loss: 1.3752 - val_accuracy: 0.6429\n",
            "Epoch 138/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.3631 - accuracy: 0.6652 - val_loss: 1.3709 - val_accuracy: 0.6429\n",
            "Epoch 139/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.3587 - accuracy: 0.6652 - val_loss: 1.3667 - val_accuracy: 0.6429\n",
            "Epoch 140/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.3544 - accuracy: 0.6674 - val_loss: 1.3625 - val_accuracy: 0.6429\n",
            "Epoch 141/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.3502 - accuracy: 0.6674 - val_loss: 1.3582 - val_accuracy: 0.6429\n",
            "Epoch 142/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.3459 - accuracy: 0.6674 - val_loss: 1.3540 - val_accuracy: 0.6429\n",
            "Epoch 143/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.3416 - accuracy: 0.6674 - val_loss: 1.3498 - val_accuracy: 0.6429\n",
            "Epoch 144/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.3374 - accuracy: 0.6674 - val_loss: 1.3456 - val_accuracy: 0.6429\n",
            "Epoch 145/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.3332 - accuracy: 0.6674 - val_loss: 1.3415 - val_accuracy: 0.6429\n",
            "Epoch 146/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.3290 - accuracy: 0.6674 - val_loss: 1.3373 - val_accuracy: 0.6429\n",
            "Epoch 147/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.3247 - accuracy: 0.6696 - val_loss: 1.3332 - val_accuracy: 0.6429\n",
            "Epoch 148/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 1.3205 - accuracy: 0.6696 - val_loss: 1.3290 - val_accuracy: 0.6429\n",
            "Epoch 149/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.3163 - accuracy: 0.6696 - val_loss: 1.3249 - val_accuracy: 0.6429\n",
            "Epoch 150/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.3122 - accuracy: 0.6696 - val_loss: 1.3208 - val_accuracy: 0.6429\n",
            "Epoch 151/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.3080 - accuracy: 0.6696 - val_loss: 1.3168 - val_accuracy: 0.6429\n",
            "Epoch 152/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.3039 - accuracy: 0.6696 - val_loss: 1.3127 - val_accuracy: 0.6429\n",
            "Epoch 153/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2997 - accuracy: 0.6696 - val_loss: 1.3086 - val_accuracy: 0.6429\n",
            "Epoch 154/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2956 - accuracy: 0.6696 - val_loss: 1.3046 - val_accuracy: 0.6429\n",
            "Epoch 155/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2915 - accuracy: 0.6674 - val_loss: 1.3005 - val_accuracy: 0.6429\n",
            "Epoch 156/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2874 - accuracy: 0.6674 - val_loss: 1.2965 - val_accuracy: 0.6429\n",
            "Epoch 157/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2834 - accuracy: 0.6696 - val_loss: 1.2925 - val_accuracy: 0.6429\n",
            "Epoch 158/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2793 - accuracy: 0.6696 - val_loss: 1.2885 - val_accuracy: 0.6429\n",
            "Epoch 159/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2753 - accuracy: 0.6696 - val_loss: 1.2845 - val_accuracy: 0.6429\n",
            "Epoch 160/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2712 - accuracy: 0.6696 - val_loss: 1.2805 - val_accuracy: 0.6429\n",
            "Epoch 161/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2672 - accuracy: 0.6696 - val_loss: 1.2766 - val_accuracy: 0.6429\n",
            "Epoch 162/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2632 - accuracy: 0.6696 - val_loss: 1.2727 - val_accuracy: 0.6429\n",
            "Epoch 163/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2592 - accuracy: 0.6696 - val_loss: 1.2687 - val_accuracy: 0.6429\n",
            "Epoch 164/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2552 - accuracy: 0.6696 - val_loss: 1.2649 - val_accuracy: 0.6429\n",
            "Epoch 165/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2513 - accuracy: 0.6696 - val_loss: 1.2610 - val_accuracy: 0.6429\n",
            "Epoch 166/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2474 - accuracy: 0.6717 - val_loss: 1.2571 - val_accuracy: 0.6429\n",
            "Epoch 167/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2434 - accuracy: 0.6717 - val_loss: 1.2533 - val_accuracy: 0.6429\n",
            "Epoch 168/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2395 - accuracy: 0.6739 - val_loss: 1.2494 - val_accuracy: 0.6429\n",
            "Epoch 169/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2356 - accuracy: 0.6761 - val_loss: 1.2456 - val_accuracy: 0.6429\n",
            "Epoch 170/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2317 - accuracy: 0.6739 - val_loss: 1.2418 - val_accuracy: 0.6429\n",
            "Epoch 171/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2278 - accuracy: 0.6739 - val_loss: 1.2379 - val_accuracy: 0.6429\n",
            "Epoch 172/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 1.2239 - accuracy: 0.6783 - val_loss: 1.2342 - val_accuracy: 0.6429\n",
            "Epoch 173/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2201 - accuracy: 0.6783 - val_loss: 1.2304 - val_accuracy: 0.6429\n",
            "Epoch 174/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2163 - accuracy: 0.6783 - val_loss: 1.2266 - val_accuracy: 0.6429\n",
            "Epoch 175/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2124 - accuracy: 0.6783 - val_loss: 1.2229 - val_accuracy: 0.6429\n",
            "Epoch 176/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2086 - accuracy: 0.6783 - val_loss: 1.2191 - val_accuracy: 0.6429\n",
            "Epoch 177/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2048 - accuracy: 0.6783 - val_loss: 1.2154 - val_accuracy: 0.6494\n",
            "Epoch 178/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2010 - accuracy: 0.6783 - val_loss: 1.2117 - val_accuracy: 0.6494\n",
            "Epoch 179/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1973 - accuracy: 0.6783 - val_loss: 1.2080 - val_accuracy: 0.6494\n",
            "Epoch 180/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1935 - accuracy: 0.6804 - val_loss: 1.2043 - val_accuracy: 0.6494\n",
            "Epoch 181/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1898 - accuracy: 0.6804 - val_loss: 1.2007 - val_accuracy: 0.6494\n",
            "Epoch 182/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1860 - accuracy: 0.6804 - val_loss: 1.1970 - val_accuracy: 0.6558\n",
            "Epoch 183/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1823 - accuracy: 0.6804 - val_loss: 1.1934 - val_accuracy: 0.6558\n",
            "Epoch 184/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1786 - accuracy: 0.6804 - val_loss: 1.1898 - val_accuracy: 0.6558\n",
            "Epoch 185/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1749 - accuracy: 0.6804 - val_loss: 1.1862 - val_accuracy: 0.6558\n",
            "Epoch 186/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1712 - accuracy: 0.6804 - val_loss: 1.1825 - val_accuracy: 0.6558\n",
            "Epoch 187/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1676 - accuracy: 0.6804 - val_loss: 1.1790 - val_accuracy: 0.6558\n",
            "Epoch 188/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1639 - accuracy: 0.6804 - val_loss: 1.1754 - val_accuracy: 0.6558\n",
            "Epoch 189/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1603 - accuracy: 0.6804 - val_loss: 1.1718 - val_accuracy: 0.6558\n",
            "Epoch 190/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1566 - accuracy: 0.6804 - val_loss: 1.1683 - val_accuracy: 0.6558\n",
            "Epoch 191/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 1.1530 - accuracy: 0.6804 - val_loss: 1.1648 - val_accuracy: 0.6558\n",
            "Epoch 192/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1494 - accuracy: 0.6804 - val_loss: 1.1613 - val_accuracy: 0.6558\n",
            "Epoch 193/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1458 - accuracy: 0.6804 - val_loss: 1.1577 - val_accuracy: 0.6558\n",
            "Epoch 194/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1422 - accuracy: 0.6826 - val_loss: 1.1543 - val_accuracy: 0.6558\n",
            "Epoch 195/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1387 - accuracy: 0.6848 - val_loss: 1.1508 - val_accuracy: 0.6558\n",
            "Epoch 196/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1351 - accuracy: 0.6848 - val_loss: 1.1473 - val_accuracy: 0.6623\n",
            "Epoch 197/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1315 - accuracy: 0.6848 - val_loss: 1.1439 - val_accuracy: 0.6623\n",
            "Epoch 198/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1280 - accuracy: 0.6848 - val_loss: 1.1405 - val_accuracy: 0.6688\n",
            "Epoch 199/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1245 - accuracy: 0.6848 - val_loss: 1.1370 - val_accuracy: 0.6688\n",
            "Epoch 200/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1210 - accuracy: 0.6848 - val_loss: 1.1337 - val_accuracy: 0.6558\n",
            "Epoch 201/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1175 - accuracy: 0.6848 - val_loss: 1.1302 - val_accuracy: 0.6558\n",
            "Epoch 202/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1140 - accuracy: 0.6848 - val_loss: 1.1269 - val_accuracy: 0.6558\n",
            "Epoch 203/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1105 - accuracy: 0.6848 - val_loss: 1.1235 - val_accuracy: 0.6623\n",
            "Epoch 204/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1070 - accuracy: 0.6848 - val_loss: 1.1202 - val_accuracy: 0.6623\n",
            "Epoch 205/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1036 - accuracy: 0.6848 - val_loss: 1.1169 - val_accuracy: 0.6623\n",
            "Epoch 206/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.1001 - accuracy: 0.6848 - val_loss: 1.1135 - val_accuracy: 0.6623\n",
            "Epoch 207/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0967 - accuracy: 0.6848 - val_loss: 1.1102 - val_accuracy: 0.6623\n",
            "Epoch 208/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0933 - accuracy: 0.6848 - val_loss: 1.1069 - val_accuracy: 0.6623\n",
            "Epoch 209/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0898 - accuracy: 0.6848 - val_loss: 1.1036 - val_accuracy: 0.6623\n",
            "Epoch 210/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0864 - accuracy: 0.6848 - val_loss: 1.1003 - val_accuracy: 0.6623\n",
            "Epoch 211/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0830 - accuracy: 0.6848 - val_loss: 1.0971 - val_accuracy: 0.6623\n",
            "Epoch 212/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0796 - accuracy: 0.6848 - val_loss: 1.0938 - val_accuracy: 0.6623\n",
            "Epoch 213/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0763 - accuracy: 0.6848 - val_loss: 1.0905 - val_accuracy: 0.6623\n",
            "Epoch 214/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0729 - accuracy: 0.6848 - val_loss: 1.0873 - val_accuracy: 0.6623\n",
            "Epoch 215/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0695 - accuracy: 0.6848 - val_loss: 1.0841 - val_accuracy: 0.6623\n",
            "Epoch 216/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0662 - accuracy: 0.6848 - val_loss: 1.0808 - val_accuracy: 0.6623\n",
            "Epoch 217/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 1.0628 - accuracy: 0.6848 - val_loss: 1.0776 - val_accuracy: 0.6688\n",
            "Epoch 218/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0595 - accuracy: 0.6870 - val_loss: 1.0744 - val_accuracy: 0.6753\n",
            "Epoch 219/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0561 - accuracy: 0.6913 - val_loss: 1.0712 - val_accuracy: 0.6753\n",
            "Epoch 220/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0528 - accuracy: 0.6913 - val_loss: 1.0681 - val_accuracy: 0.6753\n",
            "Epoch 221/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0496 - accuracy: 0.6913 - val_loss: 1.0649 - val_accuracy: 0.6753\n",
            "Epoch 222/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0462 - accuracy: 0.6913 - val_loss: 1.0618 - val_accuracy: 0.6753\n",
            "Epoch 223/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0430 - accuracy: 0.6913 - val_loss: 1.0586 - val_accuracy: 0.6753\n",
            "Epoch 224/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0397 - accuracy: 0.6913 - val_loss: 1.0555 - val_accuracy: 0.6818\n",
            "Epoch 225/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0364 - accuracy: 0.6935 - val_loss: 1.0524 - val_accuracy: 0.6883\n",
            "Epoch 226/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0332 - accuracy: 0.6935 - val_loss: 1.0493 - val_accuracy: 0.6883\n",
            "Epoch 227/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0300 - accuracy: 0.6935 - val_loss: 1.0462 - val_accuracy: 0.6948\n",
            "Epoch 228/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0267 - accuracy: 0.6957 - val_loss: 1.0431 - val_accuracy: 0.6948\n",
            "Epoch 229/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0235 - accuracy: 0.6978 - val_loss: 1.0401 - val_accuracy: 0.6948\n",
            "Epoch 230/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0203 - accuracy: 0.6978 - val_loss: 1.0371 - val_accuracy: 0.6948\n",
            "Epoch 231/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0171 - accuracy: 0.7022 - val_loss: 1.0340 - val_accuracy: 0.6948\n",
            "Epoch 232/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0139 - accuracy: 0.7022 - val_loss: 1.0311 - val_accuracy: 0.6948\n",
            "Epoch 233/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0108 - accuracy: 0.7022 - val_loss: 1.0281 - val_accuracy: 0.7013\n",
            "Epoch 234/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0076 - accuracy: 0.7000 - val_loss: 1.0251 - val_accuracy: 0.7013\n",
            "Epoch 235/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0044 - accuracy: 0.7000 - val_loss: 1.0222 - val_accuracy: 0.7013\n",
            "Epoch 236/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.0013 - accuracy: 0.7000 - val_loss: 1.0192 - val_accuracy: 0.6948\n",
            "Epoch 237/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9983 - accuracy: 0.7000 - val_loss: 1.0163 - val_accuracy: 0.6948\n",
            "Epoch 238/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9952 - accuracy: 0.7000 - val_loss: 1.0134 - val_accuracy: 0.7013\n",
            "Epoch 239/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9921 - accuracy: 0.7022 - val_loss: 1.0104 - val_accuracy: 0.7013\n",
            "Epoch 240/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9891 - accuracy: 0.7043 - val_loss: 1.0075 - val_accuracy: 0.7013\n",
            "Epoch 241/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9860 - accuracy: 0.7043 - val_loss: 1.0047 - val_accuracy: 0.7013\n",
            "Epoch 242/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9830 - accuracy: 0.7043 - val_loss: 1.0018 - val_accuracy: 0.7078\n",
            "Epoch 243/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9800 - accuracy: 0.7087 - val_loss: 0.9990 - val_accuracy: 0.7208\n",
            "Epoch 244/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9771 - accuracy: 0.7109 - val_loss: 0.9962 - val_accuracy: 0.7208\n",
            "Epoch 245/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9741 - accuracy: 0.7130 - val_loss: 0.9934 - val_accuracy: 0.7208\n",
            "Epoch 246/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9712 - accuracy: 0.7130 - val_loss: 0.9906 - val_accuracy: 0.7208\n",
            "Epoch 247/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.9683 - accuracy: 0.7174 - val_loss: 0.9878 - val_accuracy: 0.7208\n",
            "Epoch 248/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9654 - accuracy: 0.7152 - val_loss: 0.9851 - val_accuracy: 0.7208\n",
            "Epoch 249/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9625 - accuracy: 0.7152 - val_loss: 0.9823 - val_accuracy: 0.7208\n",
            "Epoch 250/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9596 - accuracy: 0.7130 - val_loss: 0.9796 - val_accuracy: 0.7208\n",
            "Epoch 251/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9568 - accuracy: 0.7109 - val_loss: 0.9769 - val_accuracy: 0.7208\n",
            "Epoch 252/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9539 - accuracy: 0.7130 - val_loss: 0.9742 - val_accuracy: 0.7273\n",
            "Epoch 253/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9511 - accuracy: 0.7174 - val_loss: 0.9716 - val_accuracy: 0.7273\n",
            "Epoch 254/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9483 - accuracy: 0.7196 - val_loss: 0.9689 - val_accuracy: 0.7273\n",
            "Epoch 255/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9455 - accuracy: 0.7196 - val_loss: 0.9662 - val_accuracy: 0.7273\n",
            "Epoch 256/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9428 - accuracy: 0.7217 - val_loss: 0.9636 - val_accuracy: 0.7273\n",
            "Epoch 257/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9400 - accuracy: 0.7239 - val_loss: 0.9610 - val_accuracy: 0.7273\n",
            "Epoch 258/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9372 - accuracy: 0.7239 - val_loss: 0.9584 - val_accuracy: 0.7273\n",
            "Epoch 259/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9345 - accuracy: 0.7261 - val_loss: 0.9558 - val_accuracy: 0.7273\n",
            "Epoch 260/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9317 - accuracy: 0.7261 - val_loss: 0.9532 - val_accuracy: 0.7273\n",
            "Epoch 261/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9290 - accuracy: 0.7261 - val_loss: 0.9506 - val_accuracy: 0.7273\n",
            "Epoch 262/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9263 - accuracy: 0.7261 - val_loss: 0.9481 - val_accuracy: 0.7273\n",
            "Epoch 263/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9237 - accuracy: 0.7283 - val_loss: 0.9456 - val_accuracy: 0.7273\n",
            "Epoch 264/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9210 - accuracy: 0.7326 - val_loss: 0.9430 - val_accuracy: 0.7273\n",
            "Epoch 265/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9183 - accuracy: 0.7304 - val_loss: 0.9405 - val_accuracy: 0.7273\n",
            "Epoch 266/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9157 - accuracy: 0.7348 - val_loss: 0.9380 - val_accuracy: 0.7273\n",
            "Epoch 267/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.9130 - accuracy: 0.7370 - val_loss: 0.9356 - val_accuracy: 0.7273\n",
            "Epoch 268/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9104 - accuracy: 0.7413 - val_loss: 0.9331 - val_accuracy: 0.7273\n",
            "Epoch 269/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9078 - accuracy: 0.7391 - val_loss: 0.9306 - val_accuracy: 0.7273\n",
            "Epoch 270/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9052 - accuracy: 0.7391 - val_loss: 0.9282 - val_accuracy: 0.7273\n",
            "Epoch 271/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9026 - accuracy: 0.7391 - val_loss: 0.9258 - val_accuracy: 0.7273\n",
            "Epoch 272/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9001 - accuracy: 0.7413 - val_loss: 0.9234 - val_accuracy: 0.7273\n",
            "Epoch 273/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8975 - accuracy: 0.7413 - val_loss: 0.9210 - val_accuracy: 0.7273\n",
            "Epoch 274/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8950 - accuracy: 0.7435 - val_loss: 0.9186 - val_accuracy: 0.7273\n",
            "Epoch 275/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8925 - accuracy: 0.7413 - val_loss: 0.9163 - val_accuracy: 0.7208\n",
            "Epoch 276/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8900 - accuracy: 0.7413 - val_loss: 0.9139 - val_accuracy: 0.7208\n",
            "Epoch 277/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.8875 - accuracy: 0.7413 - val_loss: 0.9116 - val_accuracy: 0.7208\n",
            "Epoch 278/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8850 - accuracy: 0.7413 - val_loss: 0.9093 - val_accuracy: 0.7208\n",
            "Epoch 279/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8826 - accuracy: 0.7413 - val_loss: 0.9070 - val_accuracy: 0.7208\n",
            "Epoch 280/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8801 - accuracy: 0.7413 - val_loss: 0.9046 - val_accuracy: 0.7208\n",
            "Epoch 281/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8777 - accuracy: 0.7413 - val_loss: 0.9023 - val_accuracy: 0.7208\n",
            "Epoch 282/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8752 - accuracy: 0.7413 - val_loss: 0.9000 - val_accuracy: 0.7208\n",
            "Epoch 283/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8728 - accuracy: 0.7413 - val_loss: 0.8978 - val_accuracy: 0.7208\n",
            "Epoch 284/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8704 - accuracy: 0.7413 - val_loss: 0.8956 - val_accuracy: 0.7208\n",
            "Epoch 285/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8681 - accuracy: 0.7413 - val_loss: 0.8933 - val_accuracy: 0.7208\n",
            "Epoch 286/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8657 - accuracy: 0.7413 - val_loss: 0.8911 - val_accuracy: 0.7208\n",
            "Epoch 287/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8634 - accuracy: 0.7435 - val_loss: 0.8889 - val_accuracy: 0.7208\n",
            "Epoch 288/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8610 - accuracy: 0.7435 - val_loss: 0.8867 - val_accuracy: 0.7208\n",
            "Epoch 289/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8587 - accuracy: 0.7435 - val_loss: 0.8845 - val_accuracy: 0.7208\n",
            "Epoch 290/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8564 - accuracy: 0.7457 - val_loss: 0.8823 - val_accuracy: 0.7273\n",
            "Epoch 291/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8541 - accuracy: 0.7457 - val_loss: 0.8802 - val_accuracy: 0.7273\n",
            "Epoch 292/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.8518 - accuracy: 0.7457 - val_loss: 0.8780 - val_accuracy: 0.7273\n",
            "Epoch 293/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8496 - accuracy: 0.7457 - val_loss: 0.8758 - val_accuracy: 0.7208\n",
            "Epoch 294/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8473 - accuracy: 0.7457 - val_loss: 0.8737 - val_accuracy: 0.7208\n",
            "Epoch 295/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8451 - accuracy: 0.7478 - val_loss: 0.8716 - val_accuracy: 0.7208\n",
            "Epoch 296/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8428 - accuracy: 0.7478 - val_loss: 0.8695 - val_accuracy: 0.7208\n",
            "Epoch 297/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8406 - accuracy: 0.7435 - val_loss: 0.8674 - val_accuracy: 0.7208\n",
            "Epoch 298/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8385 - accuracy: 0.7457 - val_loss: 0.8653 - val_accuracy: 0.7208\n",
            "Epoch 299/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8363 - accuracy: 0.7500 - val_loss: 0.8633 - val_accuracy: 0.7208\n",
            "Epoch 300/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8341 - accuracy: 0.7522 - val_loss: 0.8613 - val_accuracy: 0.7208\n",
            "Epoch 301/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8319 - accuracy: 0.7522 - val_loss: 0.8592 - val_accuracy: 0.7208\n",
            "Epoch 302/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8298 - accuracy: 0.7522 - val_loss: 0.8572 - val_accuracy: 0.7208\n",
            "Epoch 303/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8277 - accuracy: 0.7543 - val_loss: 0.8552 - val_accuracy: 0.7208\n",
            "Epoch 304/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8255 - accuracy: 0.7543 - val_loss: 0.8532 - val_accuracy: 0.7208\n",
            "Epoch 305/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8234 - accuracy: 0.7587 - val_loss: 0.8512 - val_accuracy: 0.7208\n",
            "Epoch 306/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8213 - accuracy: 0.7587 - val_loss: 0.8492 - val_accuracy: 0.7208\n",
            "Epoch 307/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.8192 - accuracy: 0.7609 - val_loss: 0.8472 - val_accuracy: 0.7273\n",
            "Epoch 308/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.8171 - accuracy: 0.7630 - val_loss: 0.8453 - val_accuracy: 0.7273\n",
            "Epoch 309/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8151 - accuracy: 0.7630 - val_loss: 0.8433 - val_accuracy: 0.7273\n",
            "Epoch 310/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.8130 - accuracy: 0.7652 - val_loss: 0.8414 - val_accuracy: 0.7273\n",
            "Epoch 311/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8109 - accuracy: 0.7674 - val_loss: 0.8394 - val_accuracy: 0.7273\n",
            "Epoch 312/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8089 - accuracy: 0.7674 - val_loss: 0.8375 - val_accuracy: 0.7273\n",
            "Epoch 313/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8069 - accuracy: 0.7674 - val_loss: 0.8356 - val_accuracy: 0.7273\n",
            "Epoch 314/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.8049 - accuracy: 0.7674 - val_loss: 0.8337 - val_accuracy: 0.7273\n",
            "Epoch 315/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8029 - accuracy: 0.7674 - val_loss: 0.8319 - val_accuracy: 0.7273\n",
            "Epoch 316/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8009 - accuracy: 0.7696 - val_loss: 0.8300 - val_accuracy: 0.7338\n",
            "Epoch 317/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7990 - accuracy: 0.7696 - val_loss: 0.8282 - val_accuracy: 0.7338\n",
            "Epoch 318/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7970 - accuracy: 0.7696 - val_loss: 0.8263 - val_accuracy: 0.7338\n",
            "Epoch 319/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7951 - accuracy: 0.7696 - val_loss: 0.8245 - val_accuracy: 0.7338\n",
            "Epoch 320/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7931 - accuracy: 0.7696 - val_loss: 0.8227 - val_accuracy: 0.7338\n",
            "Epoch 321/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.7912 - accuracy: 0.7717 - val_loss: 0.8209 - val_accuracy: 0.7338\n",
            "Epoch 322/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7894 - accuracy: 0.7717 - val_loss: 0.8191 - val_accuracy: 0.7338\n",
            "Epoch 323/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7874 - accuracy: 0.7739 - val_loss: 0.8173 - val_accuracy: 0.7338\n",
            "Epoch 324/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7856 - accuracy: 0.7717 - val_loss: 0.8156 - val_accuracy: 0.7338\n",
            "Epoch 325/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7837 - accuracy: 0.7717 - val_loss: 0.8138 - val_accuracy: 0.7338\n",
            "Epoch 326/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7818 - accuracy: 0.7739 - val_loss: 0.8120 - val_accuracy: 0.7403\n",
            "Epoch 327/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.7800 - accuracy: 0.7739 - val_loss: 0.8104 - val_accuracy: 0.7403\n",
            "Epoch 328/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.7782 - accuracy: 0.7739 - val_loss: 0.8086 - val_accuracy: 0.7403\n",
            "Epoch 329/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7763 - accuracy: 0.7761 - val_loss: 0.8069 - val_accuracy: 0.7403\n",
            "Epoch 330/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7745 - accuracy: 0.7739 - val_loss: 0.8053 - val_accuracy: 0.7403\n",
            "Epoch 331/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7727 - accuracy: 0.7761 - val_loss: 0.8036 - val_accuracy: 0.7468\n",
            "Epoch 332/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7710 - accuracy: 0.7761 - val_loss: 0.8019 - val_accuracy: 0.7468\n",
            "Epoch 333/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7692 - accuracy: 0.7761 - val_loss: 0.8002 - val_accuracy: 0.7468\n",
            "Epoch 334/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7674 - accuracy: 0.7761 - val_loss: 0.7986 - val_accuracy: 0.7468\n",
            "Epoch 335/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.7657 - accuracy: 0.7761 - val_loss: 0.7970 - val_accuracy: 0.7403\n",
            "Epoch 336/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7639 - accuracy: 0.7761 - val_loss: 0.7954 - val_accuracy: 0.7403\n",
            "Epoch 337/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7622 - accuracy: 0.7761 - val_loss: 0.7937 - val_accuracy: 0.7403\n",
            "Epoch 338/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7605 - accuracy: 0.7783 - val_loss: 0.7922 - val_accuracy: 0.7403\n",
            "Epoch 339/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.7588 - accuracy: 0.7783 - val_loss: 0.7906 - val_accuracy: 0.7468\n",
            "Epoch 340/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7571 - accuracy: 0.7783 - val_loss: 0.7890 - val_accuracy: 0.7532\n",
            "Epoch 341/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7554 - accuracy: 0.7739 - val_loss: 0.7875 - val_accuracy: 0.7532\n",
            "Epoch 342/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7537 - accuracy: 0.7739 - val_loss: 0.7859 - val_accuracy: 0.7532\n",
            "Epoch 343/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7520 - accuracy: 0.7739 - val_loss: 0.7844 - val_accuracy: 0.7532\n",
            "Epoch 344/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7504 - accuracy: 0.7739 - val_loss: 0.7828 - val_accuracy: 0.7532\n",
            "Epoch 345/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7487 - accuracy: 0.7739 - val_loss: 0.7814 - val_accuracy: 0.7468\n",
            "Epoch 346/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7471 - accuracy: 0.7717 - val_loss: 0.7798 - val_accuracy: 0.7468\n",
            "Epoch 347/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7455 - accuracy: 0.7717 - val_loss: 0.7784 - val_accuracy: 0.7468\n",
            "Epoch 348/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7439 - accuracy: 0.7717 - val_loss: 0.7769 - val_accuracy: 0.7468\n",
            "Epoch 349/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7423 - accuracy: 0.7761 - val_loss: 0.7754 - val_accuracy: 0.7468\n",
            "Epoch 350/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7407 - accuracy: 0.7761 - val_loss: 0.7740 - val_accuracy: 0.7468\n",
            "Epoch 351/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7391 - accuracy: 0.7783 - val_loss: 0.7725 - val_accuracy: 0.7468\n",
            "Epoch 352/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7783 - val_loss: 0.7710 - val_accuracy: 0.7468\n",
            "Epoch 353/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7360 - accuracy: 0.7783 - val_loss: 0.7696 - val_accuracy: 0.7468\n",
            "Epoch 354/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7344 - accuracy: 0.7804 - val_loss: 0.7682 - val_accuracy: 0.7468\n",
            "Epoch 355/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.7329 - accuracy: 0.7804 - val_loss: 0.7668 - val_accuracy: 0.7468\n",
            "Epoch 356/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7313 - accuracy: 0.7804 - val_loss: 0.7654 - val_accuracy: 0.7468\n",
            "Epoch 357/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7298 - accuracy: 0.7804 - val_loss: 0.7640 - val_accuracy: 0.7468\n",
            "Epoch 358/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7283 - accuracy: 0.7783 - val_loss: 0.7627 - val_accuracy: 0.7468\n",
            "Epoch 359/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.7268 - accuracy: 0.7783 - val_loss: 0.7613 - val_accuracy: 0.7468\n",
            "Epoch 360/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7253 - accuracy: 0.7783 - val_loss: 0.7599 - val_accuracy: 0.7468\n",
            "Epoch 361/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7238 - accuracy: 0.7783 - val_loss: 0.7586 - val_accuracy: 0.7468\n",
            "Epoch 362/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7223 - accuracy: 0.7804 - val_loss: 0.7572 - val_accuracy: 0.7468\n",
            "Epoch 363/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7209 - accuracy: 0.7783 - val_loss: 0.7559 - val_accuracy: 0.7468\n",
            "Epoch 364/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7194 - accuracy: 0.7804 - val_loss: 0.7545 - val_accuracy: 0.7468\n",
            "Epoch 365/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7179 - accuracy: 0.7804 - val_loss: 0.7532 - val_accuracy: 0.7532\n",
            "Epoch 366/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7165 - accuracy: 0.7804 - val_loss: 0.7520 - val_accuracy: 0.7532\n",
            "Epoch 367/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7151 - accuracy: 0.7804 - val_loss: 0.7507 - val_accuracy: 0.7532\n",
            "Epoch 368/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7137 - accuracy: 0.7804 - val_loss: 0.7494 - val_accuracy: 0.7532\n",
            "Epoch 369/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7123 - accuracy: 0.7804 - val_loss: 0.7481 - val_accuracy: 0.7532\n",
            "Epoch 370/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.7109 - accuracy: 0.7804 - val_loss: 0.7468 - val_accuracy: 0.7597\n",
            "Epoch 371/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7095 - accuracy: 0.7804 - val_loss: 0.7456 - val_accuracy: 0.7597\n",
            "Epoch 372/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.7081 - accuracy: 0.7804 - val_loss: 0.7443 - val_accuracy: 0.7597\n",
            "Epoch 373/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7068 - accuracy: 0.7804 - val_loss: 0.7431 - val_accuracy: 0.7662\n",
            "Epoch 374/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7054 - accuracy: 0.7783 - val_loss: 0.7419 - val_accuracy: 0.7662\n",
            "Epoch 375/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7041 - accuracy: 0.7783 - val_loss: 0.7406 - val_accuracy: 0.7662\n",
            "Epoch 376/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7027 - accuracy: 0.7804 - val_loss: 0.7394 - val_accuracy: 0.7662\n",
            "Epoch 377/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.7014 - accuracy: 0.7804 - val_loss: 0.7382 - val_accuracy: 0.7662\n",
            "Epoch 378/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7001 - accuracy: 0.7804 - val_loss: 0.7369 - val_accuracy: 0.7662\n",
            "Epoch 379/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6987 - accuracy: 0.7804 - val_loss: 0.7358 - val_accuracy: 0.7662\n",
            "Epoch 380/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6974 - accuracy: 0.7804 - val_loss: 0.7346 - val_accuracy: 0.7662\n",
            "Epoch 381/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6961 - accuracy: 0.7804 - val_loss: 0.7334 - val_accuracy: 0.7662\n",
            "Epoch 382/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6948 - accuracy: 0.7826 - val_loss: 0.7323 - val_accuracy: 0.7662\n",
            "Epoch 383/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.7826 - val_loss: 0.7311 - val_accuracy: 0.7727\n",
            "Epoch 384/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.7826 - val_loss: 0.7300 - val_accuracy: 0.7727\n",
            "Epoch 385/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.7826 - val_loss: 0.7288 - val_accuracy: 0.7727\n",
            "Epoch 386/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.7870 - val_loss: 0.7277 - val_accuracy: 0.7727\n",
            "Epoch 387/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.7848 - val_loss: 0.7266 - val_accuracy: 0.7727\n",
            "Epoch 388/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.7848 - val_loss: 0.7254 - val_accuracy: 0.7727\n",
            "Epoch 389/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6860 - accuracy: 0.7870 - val_loss: 0.7243 - val_accuracy: 0.7792\n",
            "Epoch 390/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.7870 - val_loss: 0.7233 - val_accuracy: 0.7792\n",
            "Epoch 391/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.7870 - val_loss: 0.7222 - val_accuracy: 0.7792\n",
            "Epoch 392/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.7870 - val_loss: 0.7210 - val_accuracy: 0.7792\n",
            "Epoch 393/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.7870 - val_loss: 0.7200 - val_accuracy: 0.7792\n",
            "Epoch 394/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.7891 - val_loss: 0.7189 - val_accuracy: 0.7792\n",
            "Epoch 395/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6787 - accuracy: 0.7891 - val_loss: 0.7178 - val_accuracy: 0.7792\n",
            "Epoch 396/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6775 - accuracy: 0.7891 - val_loss: 0.7168 - val_accuracy: 0.7792\n",
            "Epoch 397/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6763 - accuracy: 0.7913 - val_loss: 0.7157 - val_accuracy: 0.7792\n",
            "Epoch 398/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6751 - accuracy: 0.7913 - val_loss: 0.7146 - val_accuracy: 0.7792\n",
            "Epoch 399/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6739 - accuracy: 0.7913 - val_loss: 0.7135 - val_accuracy: 0.7792\n",
            "Epoch 400/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.7891 - val_loss: 0.7125 - val_accuracy: 0.7857\n",
            "Epoch 401/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6716 - accuracy: 0.7891 - val_loss: 0.7115 - val_accuracy: 0.7857\n",
            "Epoch 402/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6704 - accuracy: 0.7891 - val_loss: 0.7105 - val_accuracy: 0.7857\n",
            "Epoch 403/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.7891 - val_loss: 0.7095 - val_accuracy: 0.7857\n",
            "Epoch 404/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6682 - accuracy: 0.7891 - val_loss: 0.7084 - val_accuracy: 0.7857\n",
            "Epoch 405/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.7891 - val_loss: 0.7074 - val_accuracy: 0.7857\n",
            "Epoch 406/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6659 - accuracy: 0.7891 - val_loss: 0.7064 - val_accuracy: 0.7857\n",
            "Epoch 407/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6648 - accuracy: 0.7891 - val_loss: 0.7054 - val_accuracy: 0.7857\n",
            "Epoch 408/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6637 - accuracy: 0.7891 - val_loss: 0.7044 - val_accuracy: 0.7857\n",
            "Epoch 409/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.7891 - val_loss: 0.7035 - val_accuracy: 0.7857\n",
            "Epoch 410/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.7891 - val_loss: 0.7025 - val_accuracy: 0.7857\n",
            "Epoch 411/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.7891 - val_loss: 0.7015 - val_accuracy: 0.7792\n",
            "Epoch 412/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6594 - accuracy: 0.7913 - val_loss: 0.7006 - val_accuracy: 0.7792\n",
            "Epoch 413/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6583 - accuracy: 0.7913 - val_loss: 0.6997 - val_accuracy: 0.7792\n",
            "Epoch 414/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6573 - accuracy: 0.7913 - val_loss: 0.6987 - val_accuracy: 0.7792\n",
            "Epoch 415/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6562 - accuracy: 0.7913 - val_loss: 0.6978 - val_accuracy: 0.7792\n",
            "Epoch 416/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6552 - accuracy: 0.7913 - val_loss: 0.6968 - val_accuracy: 0.7727\n",
            "Epoch 417/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.7913 - val_loss: 0.6959 - val_accuracy: 0.7662\n",
            "Epoch 418/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6531 - accuracy: 0.7913 - val_loss: 0.6950 - val_accuracy: 0.7662\n",
            "Epoch 419/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6521 - accuracy: 0.7913 - val_loss: 0.6941 - val_accuracy: 0.7662\n",
            "Epoch 420/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6511 - accuracy: 0.7913 - val_loss: 0.6932 - val_accuracy: 0.7662\n",
            "Epoch 421/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.7913 - val_loss: 0.6922 - val_accuracy: 0.7662\n",
            "Epoch 422/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6491 - accuracy: 0.7913 - val_loss: 0.6914 - val_accuracy: 0.7662\n",
            "Epoch 423/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.7891 - val_loss: 0.6905 - val_accuracy: 0.7662\n",
            "Epoch 424/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6471 - accuracy: 0.7913 - val_loss: 0.6895 - val_accuracy: 0.7662\n",
            "Epoch 425/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.7891 - val_loss: 0.6886 - val_accuracy: 0.7662\n",
            "Epoch 426/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.7891 - val_loss: 0.6877 - val_accuracy: 0.7662\n",
            "Epoch 427/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6442 - accuracy: 0.7891 - val_loss: 0.6869 - val_accuracy: 0.7662\n",
            "Epoch 428/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6432 - accuracy: 0.7891 - val_loss: 0.6860 - val_accuracy: 0.7662\n",
            "Epoch 429/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.7891 - val_loss: 0.6851 - val_accuracy: 0.7662\n",
            "Epoch 430/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6413 - accuracy: 0.7891 - val_loss: 0.6843 - val_accuracy: 0.7662\n",
            "Epoch 431/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.7913 - val_loss: 0.6835 - val_accuracy: 0.7662\n",
            "Epoch 432/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.7913 - val_loss: 0.6827 - val_accuracy: 0.7662\n",
            "Epoch 433/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6385 - accuracy: 0.7913 - val_loss: 0.6818 - val_accuracy: 0.7662\n",
            "Epoch 434/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6375 - accuracy: 0.7913 - val_loss: 0.6810 - val_accuracy: 0.7662\n",
            "Epoch 435/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.7913 - val_loss: 0.6801 - val_accuracy: 0.7662\n",
            "Epoch 436/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6357 - accuracy: 0.7913 - val_loss: 0.6793 - val_accuracy: 0.7662\n",
            "Epoch 437/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6348 - accuracy: 0.7913 - val_loss: 0.6785 - val_accuracy: 0.7662\n",
            "Epoch 438/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7913 - val_loss: 0.6777 - val_accuracy: 0.7662\n",
            "Epoch 439/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7913 - val_loss: 0.6769 - val_accuracy: 0.7662\n",
            "Epoch 440/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6320 - accuracy: 0.7913 - val_loss: 0.6761 - val_accuracy: 0.7662\n",
            "Epoch 441/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6311 - accuracy: 0.7913 - val_loss: 0.6753 - val_accuracy: 0.7662\n",
            "Epoch 442/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6303 - accuracy: 0.7913 - val_loss: 0.6745 - val_accuracy: 0.7662\n",
            "Epoch 443/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6294 - accuracy: 0.7913 - val_loss: 0.6737 - val_accuracy: 0.7662\n",
            "Epoch 444/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6285 - accuracy: 0.7913 - val_loss: 0.6729 - val_accuracy: 0.7662\n",
            "Epoch 445/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6276 - accuracy: 0.7913 - val_loss: 0.6721 - val_accuracy: 0.7662\n",
            "Epoch 446/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.7913 - val_loss: 0.6713 - val_accuracy: 0.7662\n",
            "Epoch 447/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.7913 - val_loss: 0.6705 - val_accuracy: 0.7662\n",
            "Epoch 448/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6250 - accuracy: 0.7913 - val_loss: 0.6698 - val_accuracy: 0.7662\n",
            "Epoch 449/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6241 - accuracy: 0.7913 - val_loss: 0.6690 - val_accuracy: 0.7662\n",
            "Epoch 450/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.7913 - val_loss: 0.6682 - val_accuracy: 0.7662\n",
            "Epoch 451/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.7913 - val_loss: 0.6675 - val_accuracy: 0.7662\n",
            "Epoch 452/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6216 - accuracy: 0.7935 - val_loss: 0.6667 - val_accuracy: 0.7662\n",
            "Epoch 453/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6208 - accuracy: 0.7913 - val_loss: 0.6660 - val_accuracy: 0.7662\n",
            "Epoch 454/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6199 - accuracy: 0.7935 - val_loss: 0.6653 - val_accuracy: 0.7662\n",
            "Epoch 455/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.7957 - val_loss: 0.6646 - val_accuracy: 0.7662\n",
            "Epoch 456/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.7957 - val_loss: 0.6639 - val_accuracy: 0.7727\n",
            "Epoch 457/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.7957 - val_loss: 0.6632 - val_accuracy: 0.7727\n",
            "Epoch 458/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6167 - accuracy: 0.7957 - val_loss: 0.6624 - val_accuracy: 0.7727\n",
            "Epoch 459/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6159 - accuracy: 0.7957 - val_loss: 0.6617 - val_accuracy: 0.7727\n",
            "Epoch 460/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6151 - accuracy: 0.7957 - val_loss: 0.6611 - val_accuracy: 0.7727\n",
            "Epoch 461/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6143 - accuracy: 0.7957 - val_loss: 0.6604 - val_accuracy: 0.7727\n",
            "Epoch 462/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.7957 - val_loss: 0.6596 - val_accuracy: 0.7727\n",
            "Epoch 463/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6127 - accuracy: 0.7957 - val_loss: 0.6590 - val_accuracy: 0.7727\n",
            "Epoch 464/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.7978 - val_loss: 0.6583 - val_accuracy: 0.7727\n",
            "Epoch 465/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6112 - accuracy: 0.7978 - val_loss: 0.6576 - val_accuracy: 0.7727\n",
            "Epoch 466/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6104 - accuracy: 0.7978 - val_loss: 0.6570 - val_accuracy: 0.7727\n",
            "Epoch 467/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.7978 - val_loss: 0.6563 - val_accuracy: 0.7727\n",
            "Epoch 468/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6089 - accuracy: 0.7978 - val_loss: 0.6556 - val_accuracy: 0.7727\n",
            "Epoch 469/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.7957 - val_loss: 0.6550 - val_accuracy: 0.7727\n",
            "Epoch 470/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6074 - accuracy: 0.7957 - val_loss: 0.6543 - val_accuracy: 0.7727\n",
            "Epoch 471/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6066 - accuracy: 0.7978 - val_loss: 0.6537 - val_accuracy: 0.7727\n",
            "Epoch 472/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6059 - accuracy: 0.7978 - val_loss: 0.6531 - val_accuracy: 0.7727\n",
            "Epoch 473/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.7978 - val_loss: 0.6524 - val_accuracy: 0.7727\n",
            "Epoch 474/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.7978 - val_loss: 0.6517 - val_accuracy: 0.7727\n",
            "Epoch 475/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6036 - accuracy: 0.7978 - val_loss: 0.6511 - val_accuracy: 0.7727\n",
            "Epoch 476/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6029 - accuracy: 0.7935 - val_loss: 0.6505 - val_accuracy: 0.7662\n",
            "Epoch 477/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6021 - accuracy: 0.7935 - val_loss: 0.6498 - val_accuracy: 0.7662\n",
            "Epoch 478/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6014 - accuracy: 0.7935 - val_loss: 0.6492 - val_accuracy: 0.7662\n",
            "Epoch 479/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6007 - accuracy: 0.7935 - val_loss: 0.6485 - val_accuracy: 0.7662\n",
            "Epoch 480/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.7935 - val_loss: 0.6479 - val_accuracy: 0.7662\n",
            "Epoch 481/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5993 - accuracy: 0.7935 - val_loss: 0.6474 - val_accuracy: 0.7662\n",
            "Epoch 482/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.7935 - val_loss: 0.6467 - val_accuracy: 0.7662\n",
            "Epoch 483/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5979 - accuracy: 0.7957 - val_loss: 0.6462 - val_accuracy: 0.7662\n",
            "Epoch 484/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5972 - accuracy: 0.7957 - val_loss: 0.6455 - val_accuracy: 0.7662\n",
            "Epoch 485/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 0.7957 - val_loss: 0.6450 - val_accuracy: 0.7662\n",
            "Epoch 486/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.7957 - val_loss: 0.6444 - val_accuracy: 0.7662\n",
            "Epoch 487/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5951 - accuracy: 0.7957 - val_loss: 0.6438 - val_accuracy: 0.7662\n",
            "Epoch 488/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.7957 - val_loss: 0.6433 - val_accuracy: 0.7662\n",
            "Epoch 489/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5938 - accuracy: 0.7957 - val_loss: 0.6426 - val_accuracy: 0.7662\n",
            "Epoch 490/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.7957 - val_loss: 0.6421 - val_accuracy: 0.7662\n",
            "Epoch 491/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.7957 - val_loss: 0.6415 - val_accuracy: 0.7662\n",
            "Epoch 492/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.7957 - val_loss: 0.6409 - val_accuracy: 0.7662\n",
            "Epoch 493/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.7978 - val_loss: 0.6404 - val_accuracy: 0.7662\n",
            "Epoch 494/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.7957 - val_loss: 0.6398 - val_accuracy: 0.7662\n",
            "Epoch 495/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.7978 - val_loss: 0.6392 - val_accuracy: 0.7662\n",
            "Epoch 496/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.7978 - val_loss: 0.6387 - val_accuracy: 0.7597\n",
            "Epoch 497/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.7957 - val_loss: 0.6381 - val_accuracy: 0.7597\n",
            "Epoch 498/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5879 - accuracy: 0.7957 - val_loss: 0.6376 - val_accuracy: 0.7597\n",
            "Epoch 499/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.7957 - val_loss: 0.6371 - val_accuracy: 0.7597\n",
            "Epoch 500/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5867 - accuracy: 0.7957 - val_loss: 0.6365 - val_accuracy: 0.7597\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=500, batch_size=8, verbose = 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z6ei4YpcQ7w"
      },
      "source": [
        "Evaluating the model on the Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JklD2V3HcEWv",
        "outputId": "921bc00a-ea0b-4fdd-a9d2-7d933e5bd0bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5769 - accuracy: 0.8052\n",
            "accuracy: 80.52%\n"
          ]
        }
      ],
      "source": [
        "scores = model.evaluate(X_test, y_test)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjqoIjnKcmMq"
      },
      "source": [
        "Plotting Training Accuracy VS Validation Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "AMLLdrgjcXNV",
        "outputId": "5b76cb66-29ca-47f0-b4e3-b49685a66906"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuAlEGUVcwdH"
      },
      "source": [
        "Plotting Training Loss VS Validation Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "uGd9RF7ociG6",
        "outputId": "39ea4f33-f98b-476a-d0a6-e4b2cb9c7e45"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RQd5EjzaLFS"
      },
      "source": [
        "For Phase-3 all, our parameters remain same as the previous Neural Network Model, only instead of L2 regularization, we add a Dropout of 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VXkysD9c_K4",
        "outputId": "f4c77572-24bd-4372-a87f-ca26fea83e26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 40)                360       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 40)                0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 25)                1025      \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 15)                390       \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1)                 16        \n",
            "=================================================================\n",
            "Total params: 1,791\n",
            "Trainable params: 1,791\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model_1 = Sequential()\n",
        "\n",
        "# model.add(Dense(1000, input_dim=8, init='uniform', activation='relu'))\n",
        "\n",
        "model_1.add(Dense(40, activation='relu', input_dim=8))\n",
        "model_1.add(Dropout(0.2))\n",
        "model_1.add(Dense(25, activation='relu'))\n",
        "model_1.add(Dense(15, activation='relu'))\n",
        "model_1.add(Dense(1, activation='sigmoid'))\n",
        "model_1.compile(optimizer=Adam(learning_rate= 0.00001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(model_1.summary())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sEXd-Owded6"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLDSHDX4dclH",
        "outputId": "6fe792a0-6fac-451f-d9a1-a827832281fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "58/58 [==============================] - 1s 5ms/step - loss: 0.7221 - accuracy: 0.3957 - val_loss: 0.7188 - val_accuracy: 0.4026\n",
            "Epoch 2/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7183 - accuracy: 0.4217 - val_loss: 0.7166 - val_accuracy: 0.3961\n",
            "Epoch 3/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7175 - accuracy: 0.4196 - val_loss: 0.7143 - val_accuracy: 0.3961\n",
            "Epoch 4/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7123 - accuracy: 0.4174 - val_loss: 0.7121 - val_accuracy: 0.4156\n",
            "Epoch 5/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7080 - accuracy: 0.4413 - val_loss: 0.7101 - val_accuracy: 0.4156\n",
            "Epoch 6/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7034 - accuracy: 0.4609 - val_loss: 0.7080 - val_accuracy: 0.4416\n",
            "Epoch 7/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7042 - accuracy: 0.4522 - val_loss: 0.7059 - val_accuracy: 0.4416\n",
            "Epoch 8/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6999 - accuracy: 0.4565 - val_loss: 0.7038 - val_accuracy: 0.4416\n",
            "Epoch 9/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7041 - accuracy: 0.4696 - val_loss: 0.7018 - val_accuracy: 0.4416\n",
            "Epoch 10/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7029 - accuracy: 0.4609 - val_loss: 0.6998 - val_accuracy: 0.4416\n",
            "Epoch 11/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4848 - val_loss: 0.6978 - val_accuracy: 0.4416\n",
            "Epoch 12/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5000 - val_loss: 0.6959 - val_accuracy: 0.4481\n",
            "Epoch 13/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5043 - val_loss: 0.6941 - val_accuracy: 0.4870\n",
            "Epoch 14/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.5130 - val_loss: 0.6923 - val_accuracy: 0.5195\n",
            "Epoch 15/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.4891 - val_loss: 0.6905 - val_accuracy: 0.5195\n",
            "Epoch 16/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.5326 - val_loss: 0.6886 - val_accuracy: 0.5325\n",
            "Epoch 17/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.5196 - val_loss: 0.6868 - val_accuracy: 0.5390\n",
            "Epoch 18/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6759 - accuracy: 0.5609 - val_loss: 0.6848 - val_accuracy: 0.5455\n",
            "Epoch 19/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6733 - accuracy: 0.5696 - val_loss: 0.6829 - val_accuracy: 0.5390\n",
            "Epoch 20/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6695 - accuracy: 0.5913 - val_loss: 0.6811 - val_accuracy: 0.5455\n",
            "Epoch 21/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6735 - accuracy: 0.5717 - val_loss: 0.6793 - val_accuracy: 0.5519\n",
            "Epoch 22/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6692 - accuracy: 0.6087 - val_loss: 0.6776 - val_accuracy: 0.5455\n",
            "Epoch 23/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6677 - accuracy: 0.6087 - val_loss: 0.6759 - val_accuracy: 0.5519\n",
            "Epoch 24/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6648 - accuracy: 0.6196 - val_loss: 0.6743 - val_accuracy: 0.5519\n",
            "Epoch 25/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6667 - accuracy: 0.5891 - val_loss: 0.6725 - val_accuracy: 0.5584\n",
            "Epoch 26/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6644 - accuracy: 0.5891 - val_loss: 0.6708 - val_accuracy: 0.5779\n",
            "Epoch 27/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.6587 - val_loss: 0.6691 - val_accuracy: 0.5909\n",
            "Epoch 28/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6580 - accuracy: 0.6543 - val_loss: 0.6675 - val_accuracy: 0.5909\n",
            "Epoch 29/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.6435 - val_loss: 0.6659 - val_accuracy: 0.6039\n",
            "Epoch 30/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.6717 - val_loss: 0.6643 - val_accuracy: 0.6039\n",
            "Epoch 31/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6551 - accuracy: 0.6478 - val_loss: 0.6626 - val_accuracy: 0.6104\n",
            "Epoch 32/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6523 - accuracy: 0.6587 - val_loss: 0.6610 - val_accuracy: 0.6169\n",
            "Epoch 33/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6499 - accuracy: 0.6696 - val_loss: 0.6593 - val_accuracy: 0.6299\n",
            "Epoch 34/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6506 - accuracy: 0.6674 - val_loss: 0.6578 - val_accuracy: 0.6429\n",
            "Epoch 35/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6493 - accuracy: 0.6565 - val_loss: 0.6561 - val_accuracy: 0.6429\n",
            "Epoch 36/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6436 - accuracy: 0.7087 - val_loss: 0.6544 - val_accuracy: 0.6494\n",
            "Epoch 37/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6402 - accuracy: 0.6978 - val_loss: 0.6529 - val_accuracy: 0.6429\n",
            "Epoch 38/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.6652 - val_loss: 0.6514 - val_accuracy: 0.6623\n",
            "Epoch 39/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.6978 - val_loss: 0.6499 - val_accuracy: 0.6558\n",
            "Epoch 40/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6369 - accuracy: 0.6957 - val_loss: 0.6484 - val_accuracy: 0.6688\n",
            "Epoch 41/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.7022 - val_loss: 0.6468 - val_accuracy: 0.6688\n",
            "Epoch 42/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.7130 - val_loss: 0.6454 - val_accuracy: 0.6623\n",
            "Epoch 43/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6320 - accuracy: 0.7130 - val_loss: 0.6440 - val_accuracy: 0.6623\n",
            "Epoch 44/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6324 - accuracy: 0.7043 - val_loss: 0.6424 - val_accuracy: 0.6688\n",
            "Epoch 45/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6294 - accuracy: 0.7087 - val_loss: 0.6409 - val_accuracy: 0.6753\n",
            "Epoch 46/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.7109 - val_loss: 0.6394 - val_accuracy: 0.6818\n",
            "Epoch 47/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.7457 - val_loss: 0.6379 - val_accuracy: 0.6818\n",
            "Epoch 48/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.7174 - val_loss: 0.6364 - val_accuracy: 0.6883\n",
            "Epoch 49/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6241 - accuracy: 0.7174 - val_loss: 0.6351 - val_accuracy: 0.6818\n",
            "Epoch 50/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6183 - accuracy: 0.6957 - val_loss: 0.6337 - val_accuracy: 0.6753\n",
            "Epoch 51/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.7304 - val_loss: 0.6323 - val_accuracy: 0.6753\n",
            "Epoch 52/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.7087 - val_loss: 0.6308 - val_accuracy: 0.6818\n",
            "Epoch 53/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.7348 - val_loss: 0.6294 - val_accuracy: 0.6818\n",
            "Epoch 54/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6146 - accuracy: 0.7370 - val_loss: 0.6281 - val_accuracy: 0.6883\n",
            "Epoch 55/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.6913 - val_loss: 0.6266 - val_accuracy: 0.6883\n",
            "Epoch 56/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6039 - accuracy: 0.7261 - val_loss: 0.6253 - val_accuracy: 0.6883\n",
            "Epoch 57/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.7391 - val_loss: 0.6240 - val_accuracy: 0.6883\n",
            "Epoch 58/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.7239 - val_loss: 0.6228 - val_accuracy: 0.6883\n",
            "Epoch 59/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6018 - accuracy: 0.7217 - val_loss: 0.6215 - val_accuracy: 0.6883\n",
            "Epoch 60/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6013 - accuracy: 0.7261 - val_loss: 0.6202 - val_accuracy: 0.7013\n",
            "Epoch 61/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6052 - accuracy: 0.7239 - val_loss: 0.6190 - val_accuracy: 0.7078\n",
            "Epoch 62/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6039 - accuracy: 0.7174 - val_loss: 0.6178 - val_accuracy: 0.7143\n",
            "Epoch 63/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5989 - accuracy: 0.7348 - val_loss: 0.6166 - val_accuracy: 0.7208\n",
            "Epoch 64/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5978 - accuracy: 0.7370 - val_loss: 0.6154 - val_accuracy: 0.7208\n",
            "Epoch 65/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5942 - accuracy: 0.7239 - val_loss: 0.6142 - val_accuracy: 0.7208\n",
            "Epoch 66/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5975 - accuracy: 0.7087 - val_loss: 0.6132 - val_accuracy: 0.7208\n",
            "Epoch 67/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.7217 - val_loss: 0.6120 - val_accuracy: 0.7208\n",
            "Epoch 68/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5972 - accuracy: 0.7065 - val_loss: 0.6109 - val_accuracy: 0.7338\n",
            "Epoch 69/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.7348 - val_loss: 0.6099 - val_accuracy: 0.7273\n",
            "Epoch 70/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.7174 - val_loss: 0.6087 - val_accuracy: 0.7338\n",
            "Epoch 71/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.7304 - val_loss: 0.6077 - val_accuracy: 0.7338\n",
            "Epoch 72/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7239 - val_loss: 0.6067 - val_accuracy: 0.7338\n",
            "Epoch 73/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5897 - accuracy: 0.7261 - val_loss: 0.6056 - val_accuracy: 0.7338\n",
            "Epoch 74/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5879 - accuracy: 0.6978 - val_loss: 0.6046 - val_accuracy: 0.7338\n",
            "Epoch 75/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.7457 - val_loss: 0.6036 - val_accuracy: 0.7338\n",
            "Epoch 76/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.7283 - val_loss: 0.6027 - val_accuracy: 0.7338\n",
            "Epoch 77/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.7196 - val_loss: 0.6017 - val_accuracy: 0.7338\n",
            "Epoch 78/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.7174 - val_loss: 0.6007 - val_accuracy: 0.7338\n",
            "Epoch 79/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5840 - accuracy: 0.7152 - val_loss: 0.5997 - val_accuracy: 0.7338\n",
            "Epoch 80/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.7109 - val_loss: 0.5988 - val_accuracy: 0.7273\n",
            "Epoch 81/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.7239 - val_loss: 0.5979 - val_accuracy: 0.7273\n",
            "Epoch 82/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.7217 - val_loss: 0.5970 - val_accuracy: 0.7273\n",
            "Epoch 83/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.7239 - val_loss: 0.5961 - val_accuracy: 0.7273\n",
            "Epoch 84/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5715 - accuracy: 0.7326 - val_loss: 0.5952 - val_accuracy: 0.7208\n",
            "Epoch 85/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7283 - val_loss: 0.5943 - val_accuracy: 0.7273\n",
            "Epoch 86/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.7261 - val_loss: 0.5934 - val_accuracy: 0.7273\n",
            "Epoch 87/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7239 - val_loss: 0.5924 - val_accuracy: 0.7273\n",
            "Epoch 88/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7326 - val_loss: 0.5915 - val_accuracy: 0.7273\n",
            "Epoch 89/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7348 - val_loss: 0.5906 - val_accuracy: 0.7273\n",
            "Epoch 90/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.7152 - val_loss: 0.5897 - val_accuracy: 0.7338\n",
            "Epoch 91/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.7196 - val_loss: 0.5889 - val_accuracy: 0.7338\n",
            "Epoch 92/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7304 - val_loss: 0.5880 - val_accuracy: 0.7338\n",
            "Epoch 93/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.7109 - val_loss: 0.5871 - val_accuracy: 0.7338\n",
            "Epoch 94/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.7217 - val_loss: 0.5864 - val_accuracy: 0.7338\n",
            "Epoch 95/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.7239 - val_loss: 0.5856 - val_accuracy: 0.7338\n",
            "Epoch 96/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.7283 - val_loss: 0.5849 - val_accuracy: 0.7338\n",
            "Epoch 97/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7261 - val_loss: 0.5841 - val_accuracy: 0.7338\n",
            "Epoch 98/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7152 - val_loss: 0.5833 - val_accuracy: 0.7338\n",
            "Epoch 99/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.7326 - val_loss: 0.5825 - val_accuracy: 0.7338\n",
            "Epoch 100/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7348 - val_loss: 0.5817 - val_accuracy: 0.7338\n",
            "Epoch 101/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.7087 - val_loss: 0.5810 - val_accuracy: 0.7338\n",
            "Epoch 102/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7261 - val_loss: 0.5803 - val_accuracy: 0.7338\n",
            "Epoch 103/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.7283 - val_loss: 0.5796 - val_accuracy: 0.7338\n",
            "Epoch 104/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7348 - val_loss: 0.5789 - val_accuracy: 0.7338\n",
            "Epoch 105/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7152 - val_loss: 0.5782 - val_accuracy: 0.7338\n",
            "Epoch 106/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7174 - val_loss: 0.5776 - val_accuracy: 0.7338\n",
            "Epoch 107/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5553 - accuracy: 0.7130 - val_loss: 0.5770 - val_accuracy: 0.7338\n",
            "Epoch 108/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7174 - val_loss: 0.5764 - val_accuracy: 0.7338\n",
            "Epoch 109/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.7196 - val_loss: 0.5758 - val_accuracy: 0.7338\n",
            "Epoch 110/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7152 - val_loss: 0.5752 - val_accuracy: 0.7338\n",
            "Epoch 111/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7152 - val_loss: 0.5745 - val_accuracy: 0.7338\n",
            "Epoch 112/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7087 - val_loss: 0.5739 - val_accuracy: 0.7338\n",
            "Epoch 113/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7000 - val_loss: 0.5733 - val_accuracy: 0.7338\n",
            "Epoch 114/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.7217 - val_loss: 0.5727 - val_accuracy: 0.7338\n",
            "Epoch 115/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7065 - val_loss: 0.5721 - val_accuracy: 0.7338\n",
            "Epoch 116/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7130 - val_loss: 0.5715 - val_accuracy: 0.7338\n",
            "Epoch 117/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.7239 - val_loss: 0.5709 - val_accuracy: 0.7273\n",
            "Epoch 118/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7217 - val_loss: 0.5702 - val_accuracy: 0.7273\n",
            "Epoch 119/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7239 - val_loss: 0.5697 - val_accuracy: 0.7273\n",
            "Epoch 120/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7065 - val_loss: 0.5691 - val_accuracy: 0.7273\n",
            "Epoch 121/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7304 - val_loss: 0.5684 - val_accuracy: 0.7273\n",
            "Epoch 122/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7174 - val_loss: 0.5678 - val_accuracy: 0.7273\n",
            "Epoch 123/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7370 - val_loss: 0.5672 - val_accuracy: 0.7273\n",
            "Epoch 124/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7217 - val_loss: 0.5666 - val_accuracy: 0.7273\n",
            "Epoch 125/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7457 - val_loss: 0.5662 - val_accuracy: 0.7273\n",
            "Epoch 126/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7239 - val_loss: 0.5656 - val_accuracy: 0.7273\n",
            "Epoch 127/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7174 - val_loss: 0.5651 - val_accuracy: 0.7273\n",
            "Epoch 128/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.7261 - val_loss: 0.5645 - val_accuracy: 0.7273\n",
            "Epoch 129/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7217 - val_loss: 0.5640 - val_accuracy: 0.7273\n",
            "Epoch 130/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7065 - val_loss: 0.5635 - val_accuracy: 0.7273\n",
            "Epoch 131/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7196 - val_loss: 0.5629 - val_accuracy: 0.7273\n",
            "Epoch 132/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7239 - val_loss: 0.5623 - val_accuracy: 0.7208\n",
            "Epoch 133/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7087 - val_loss: 0.5619 - val_accuracy: 0.7208\n",
            "Epoch 134/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7326 - val_loss: 0.5614 - val_accuracy: 0.7208\n",
            "Epoch 135/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7348 - val_loss: 0.5609 - val_accuracy: 0.7208\n",
            "Epoch 136/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7304 - val_loss: 0.5605 - val_accuracy: 0.7208\n",
            "Epoch 137/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7609 - val_loss: 0.5599 - val_accuracy: 0.7208\n",
            "Epoch 138/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7130 - val_loss: 0.5594 - val_accuracy: 0.7208\n",
            "Epoch 139/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5340 - accuracy: 0.7304 - val_loss: 0.5590 - val_accuracy: 0.7208\n",
            "Epoch 140/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.7348 - val_loss: 0.5586 - val_accuracy: 0.7208\n",
            "Epoch 141/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.7348 - val_loss: 0.5581 - val_accuracy: 0.7208\n",
            "Epoch 142/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7261 - val_loss: 0.5577 - val_accuracy: 0.7208\n",
            "Epoch 143/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7239 - val_loss: 0.5573 - val_accuracy: 0.7208\n",
            "Epoch 144/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7261 - val_loss: 0.5568 - val_accuracy: 0.7208\n",
            "Epoch 145/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7196 - val_loss: 0.5564 - val_accuracy: 0.7273\n",
            "Epoch 146/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7326 - val_loss: 0.5560 - val_accuracy: 0.7273\n",
            "Epoch 147/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7174 - val_loss: 0.5556 - val_accuracy: 0.7273\n",
            "Epoch 148/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7543 - val_loss: 0.5551 - val_accuracy: 0.7273\n",
            "Epoch 149/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7152 - val_loss: 0.5547 - val_accuracy: 0.7273\n",
            "Epoch 150/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7348 - val_loss: 0.5543 - val_accuracy: 0.7208\n",
            "Epoch 151/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7370 - val_loss: 0.5538 - val_accuracy: 0.7208\n",
            "Epoch 152/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7152 - val_loss: 0.5534 - val_accuracy: 0.7208\n",
            "Epoch 153/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7326 - val_loss: 0.5530 - val_accuracy: 0.7208\n",
            "Epoch 154/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7457 - val_loss: 0.5527 - val_accuracy: 0.7208\n",
            "Epoch 155/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7239 - val_loss: 0.5523 - val_accuracy: 0.7208\n",
            "Epoch 156/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7304 - val_loss: 0.5519 - val_accuracy: 0.7273\n",
            "Epoch 157/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.7283 - val_loss: 0.5515 - val_accuracy: 0.7273\n",
            "Epoch 158/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7283 - val_loss: 0.5510 - val_accuracy: 0.7338\n",
            "Epoch 159/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7217 - val_loss: 0.5507 - val_accuracy: 0.7338\n",
            "Epoch 160/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7304 - val_loss: 0.5504 - val_accuracy: 0.7338\n",
            "Epoch 161/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7413 - val_loss: 0.5500 - val_accuracy: 0.7338\n",
            "Epoch 162/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7326 - val_loss: 0.5496 - val_accuracy: 0.7338\n",
            "Epoch 163/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.7326 - val_loss: 0.5492 - val_accuracy: 0.7338\n",
            "Epoch 164/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7370 - val_loss: 0.5488 - val_accuracy: 0.7338\n",
            "Epoch 165/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7261 - val_loss: 0.5484 - val_accuracy: 0.7338\n",
            "Epoch 166/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7587 - val_loss: 0.5480 - val_accuracy: 0.7338\n",
            "Epoch 167/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7457 - val_loss: 0.5475 - val_accuracy: 0.7338\n",
            "Epoch 168/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7348 - val_loss: 0.5472 - val_accuracy: 0.7338\n",
            "Epoch 169/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7435 - val_loss: 0.5468 - val_accuracy: 0.7338\n",
            "Epoch 170/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7500 - val_loss: 0.5465 - val_accuracy: 0.7208\n",
            "Epoch 171/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7348 - val_loss: 0.5461 - val_accuracy: 0.7208\n",
            "Epoch 172/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7543 - val_loss: 0.5457 - val_accuracy: 0.7208\n",
            "Epoch 173/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7413 - val_loss: 0.5454 - val_accuracy: 0.7208\n",
            "Epoch 174/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7391 - val_loss: 0.5450 - val_accuracy: 0.7208\n",
            "Epoch 175/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7457 - val_loss: 0.5447 - val_accuracy: 0.7143\n",
            "Epoch 176/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7500 - val_loss: 0.5442 - val_accuracy: 0.7143\n",
            "Epoch 177/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7370 - val_loss: 0.5438 - val_accuracy: 0.7143\n",
            "Epoch 178/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7370 - val_loss: 0.5435 - val_accuracy: 0.7143\n",
            "Epoch 179/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7435 - val_loss: 0.5432 - val_accuracy: 0.7143\n",
            "Epoch 180/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7500 - val_loss: 0.5428 - val_accuracy: 0.7078\n",
            "Epoch 181/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7326 - val_loss: 0.5426 - val_accuracy: 0.7078\n",
            "Epoch 182/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7565 - val_loss: 0.5423 - val_accuracy: 0.7078\n",
            "Epoch 183/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7478 - val_loss: 0.5419 - val_accuracy: 0.7078\n",
            "Epoch 184/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7500 - val_loss: 0.5416 - val_accuracy: 0.7078\n",
            "Epoch 185/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7370 - val_loss: 0.5412 - val_accuracy: 0.7078\n",
            "Epoch 186/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7478 - val_loss: 0.5410 - val_accuracy: 0.7078\n",
            "Epoch 187/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7370 - val_loss: 0.5407 - val_accuracy: 0.7078\n",
            "Epoch 188/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7457 - val_loss: 0.5403 - val_accuracy: 0.7078\n",
            "Epoch 189/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7435 - val_loss: 0.5399 - val_accuracy: 0.7078\n",
            "Epoch 190/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7261 - val_loss: 0.5397 - val_accuracy: 0.7078\n",
            "Epoch 191/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7413 - val_loss: 0.5395 - val_accuracy: 0.7078\n",
            "Epoch 192/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7326 - val_loss: 0.5392 - val_accuracy: 0.7078\n",
            "Epoch 193/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7543 - val_loss: 0.5390 - val_accuracy: 0.7078\n",
            "Epoch 194/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7522 - val_loss: 0.5386 - val_accuracy: 0.7078\n",
            "Epoch 195/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7348 - val_loss: 0.5382 - val_accuracy: 0.7078\n",
            "Epoch 196/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7435 - val_loss: 0.5380 - val_accuracy: 0.7143\n",
            "Epoch 197/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7435 - val_loss: 0.5377 - val_accuracy: 0.7273\n",
            "Epoch 198/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7478 - val_loss: 0.5374 - val_accuracy: 0.7273\n",
            "Epoch 199/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7478 - val_loss: 0.5370 - val_accuracy: 0.7273\n",
            "Epoch 200/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7674 - val_loss: 0.5368 - val_accuracy: 0.7208\n",
            "Epoch 201/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7413 - val_loss: 0.5365 - val_accuracy: 0.7208\n",
            "Epoch 202/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7652 - val_loss: 0.5362 - val_accuracy: 0.7208\n",
            "Epoch 203/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7478 - val_loss: 0.5360 - val_accuracy: 0.7208\n",
            "Epoch 204/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7522 - val_loss: 0.5357 - val_accuracy: 0.7208\n",
            "Epoch 205/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7457 - val_loss: 0.5353 - val_accuracy: 0.7208\n",
            "Epoch 206/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7435 - val_loss: 0.5350 - val_accuracy: 0.7208\n",
            "Epoch 207/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7609 - val_loss: 0.5347 - val_accuracy: 0.7208\n",
            "Epoch 208/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7435 - val_loss: 0.5345 - val_accuracy: 0.7208\n",
            "Epoch 209/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7674 - val_loss: 0.5343 - val_accuracy: 0.7143\n",
            "Epoch 210/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7565 - val_loss: 0.5340 - val_accuracy: 0.7208\n",
            "Epoch 211/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7565 - val_loss: 0.5337 - val_accuracy: 0.7208\n",
            "Epoch 212/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7478 - val_loss: 0.5336 - val_accuracy: 0.7208\n",
            "Epoch 213/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7500 - val_loss: 0.5332 - val_accuracy: 0.7208\n",
            "Epoch 214/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7609 - val_loss: 0.5329 - val_accuracy: 0.7208\n",
            "Epoch 215/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7652 - val_loss: 0.5326 - val_accuracy: 0.7273\n",
            "Epoch 216/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7674 - val_loss: 0.5323 - val_accuracy: 0.7208\n",
            "Epoch 217/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7543 - val_loss: 0.5322 - val_accuracy: 0.7208\n",
            "Epoch 218/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7630 - val_loss: 0.5319 - val_accuracy: 0.7208\n",
            "Epoch 219/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7630 - val_loss: 0.5316 - val_accuracy: 0.7208\n",
            "Epoch 220/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7565 - val_loss: 0.5313 - val_accuracy: 0.7273\n",
            "Epoch 221/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7630 - val_loss: 0.5311 - val_accuracy: 0.7338\n",
            "Epoch 222/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7522 - val_loss: 0.5309 - val_accuracy: 0.7338\n",
            "Epoch 223/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7848 - val_loss: 0.5307 - val_accuracy: 0.7338\n",
            "Epoch 224/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7478 - val_loss: 0.5304 - val_accuracy: 0.7403\n",
            "Epoch 225/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7435 - val_loss: 0.5302 - val_accuracy: 0.7403\n",
            "Epoch 226/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7239 - val_loss: 0.5299 - val_accuracy: 0.7403\n",
            "Epoch 227/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7630 - val_loss: 0.5299 - val_accuracy: 0.7403\n",
            "Epoch 228/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7391 - val_loss: 0.5296 - val_accuracy: 0.7403\n",
            "Epoch 229/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7500 - val_loss: 0.5294 - val_accuracy: 0.7403\n",
            "Epoch 230/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.7543 - val_loss: 0.5292 - val_accuracy: 0.7403\n",
            "Epoch 231/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7478 - val_loss: 0.5289 - val_accuracy: 0.7403\n",
            "Epoch 232/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.7674 - val_loss: 0.5288 - val_accuracy: 0.7403\n",
            "Epoch 233/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.7565 - val_loss: 0.5286 - val_accuracy: 0.7403\n",
            "Epoch 234/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7630 - val_loss: 0.5283 - val_accuracy: 0.7403\n",
            "Epoch 235/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7630 - val_loss: 0.5281 - val_accuracy: 0.7403\n",
            "Epoch 236/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7478 - val_loss: 0.5278 - val_accuracy: 0.7403\n",
            "Epoch 237/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7587 - val_loss: 0.5277 - val_accuracy: 0.7403\n",
            "Epoch 238/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7630 - val_loss: 0.5275 - val_accuracy: 0.7403\n",
            "Epoch 239/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.7609 - val_loss: 0.5273 - val_accuracy: 0.7403\n",
            "Epoch 240/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7370 - val_loss: 0.5270 - val_accuracy: 0.7338\n",
            "Epoch 241/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7630 - val_loss: 0.5268 - val_accuracy: 0.7338\n",
            "Epoch 242/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7565 - val_loss: 0.5266 - val_accuracy: 0.7273\n",
            "Epoch 243/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7478 - val_loss: 0.5264 - val_accuracy: 0.7273\n",
            "Epoch 244/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.7370 - val_loss: 0.5263 - val_accuracy: 0.7273\n",
            "Epoch 245/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7609 - val_loss: 0.5261 - val_accuracy: 0.7403\n",
            "Epoch 246/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.7587 - val_loss: 0.5259 - val_accuracy: 0.7403\n",
            "Epoch 247/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7652 - val_loss: 0.5258 - val_accuracy: 0.7403\n",
            "Epoch 248/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.7522 - val_loss: 0.5255 - val_accuracy: 0.7338\n",
            "Epoch 249/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7457 - val_loss: 0.5254 - val_accuracy: 0.7338\n",
            "Epoch 250/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7630 - val_loss: 0.5252 - val_accuracy: 0.7273\n",
            "Epoch 251/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.7587 - val_loss: 0.5250 - val_accuracy: 0.7273\n",
            "Epoch 252/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7543 - val_loss: 0.5249 - val_accuracy: 0.7273\n",
            "Epoch 253/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.7783 - val_loss: 0.5247 - val_accuracy: 0.7273\n",
            "Epoch 254/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7609 - val_loss: 0.5245 - val_accuracy: 0.7208\n",
            "Epoch 255/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4932 - accuracy: 0.7478 - val_loss: 0.5244 - val_accuracy: 0.7273\n",
            "Epoch 256/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7587 - val_loss: 0.5241 - val_accuracy: 0.7273\n",
            "Epoch 257/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7652 - val_loss: 0.5240 - val_accuracy: 0.7273\n",
            "Epoch 258/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7761 - val_loss: 0.5238 - val_accuracy: 0.7273\n",
            "Epoch 259/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7457 - val_loss: 0.5237 - val_accuracy: 0.7273\n",
            "Epoch 260/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.7435 - val_loss: 0.5234 - val_accuracy: 0.7273\n",
            "Epoch 261/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7587 - val_loss: 0.5233 - val_accuracy: 0.7273\n",
            "Epoch 262/500\n",
            "58/58 [==============================] - 0s 4ms/step - loss: 0.4951 - accuracy: 0.7587 - val_loss: 0.5231 - val_accuracy: 0.7338\n",
            "Epoch 263/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7565 - val_loss: 0.5231 - val_accuracy: 0.7338\n",
            "Epoch 264/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7630 - val_loss: 0.5229 - val_accuracy: 0.7403\n",
            "Epoch 265/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7609 - val_loss: 0.5227 - val_accuracy: 0.7403\n",
            "Epoch 266/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7696 - val_loss: 0.5225 - val_accuracy: 0.7403\n",
            "Epoch 267/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7783 - val_loss: 0.5224 - val_accuracy: 0.7403\n",
            "Epoch 268/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7565 - val_loss: 0.5223 - val_accuracy: 0.7403\n",
            "Epoch 269/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7630 - val_loss: 0.5222 - val_accuracy: 0.7403\n",
            "Epoch 270/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7870 - val_loss: 0.5220 - val_accuracy: 0.7403\n",
            "Epoch 271/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7630 - val_loss: 0.5218 - val_accuracy: 0.7403\n",
            "Epoch 272/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.7696 - val_loss: 0.5217 - val_accuracy: 0.7403\n",
            "Epoch 273/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7609 - val_loss: 0.5216 - val_accuracy: 0.7403\n",
            "Epoch 274/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7717 - val_loss: 0.5215 - val_accuracy: 0.7468\n",
            "Epoch 275/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7587 - val_loss: 0.5213 - val_accuracy: 0.7468\n",
            "Epoch 276/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7826 - val_loss: 0.5212 - val_accuracy: 0.7468\n",
            "Epoch 277/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7696 - val_loss: 0.5211 - val_accuracy: 0.7468\n",
            "Epoch 278/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7587 - val_loss: 0.5209 - val_accuracy: 0.7468\n",
            "Epoch 279/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7587 - val_loss: 0.5208 - val_accuracy: 0.7468\n",
            "Epoch 280/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7804 - val_loss: 0.5206 - val_accuracy: 0.7468\n",
            "Epoch 281/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.7630 - val_loss: 0.5205 - val_accuracy: 0.7468\n",
            "Epoch 282/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7826 - val_loss: 0.5203 - val_accuracy: 0.7468\n",
            "Epoch 283/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7739 - val_loss: 0.5202 - val_accuracy: 0.7468\n",
            "Epoch 284/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7696 - val_loss: 0.5200 - val_accuracy: 0.7468\n",
            "Epoch 285/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7739 - val_loss: 0.5199 - val_accuracy: 0.7468\n",
            "Epoch 286/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.7674 - val_loss: 0.5198 - val_accuracy: 0.7468\n",
            "Epoch 287/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.7609 - val_loss: 0.5197 - val_accuracy: 0.7468\n",
            "Epoch 288/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7761 - val_loss: 0.5196 - val_accuracy: 0.7468\n",
            "Epoch 289/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7630 - val_loss: 0.5194 - val_accuracy: 0.7468\n",
            "Epoch 290/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7609 - val_loss: 0.5193 - val_accuracy: 0.7468\n",
            "Epoch 291/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7696 - val_loss: 0.5191 - val_accuracy: 0.7468\n",
            "Epoch 292/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7848 - val_loss: 0.5190 - val_accuracy: 0.7532\n",
            "Epoch 293/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7717 - val_loss: 0.5189 - val_accuracy: 0.7532\n",
            "Epoch 294/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7565 - val_loss: 0.5188 - val_accuracy: 0.7532\n",
            "Epoch 295/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7717 - val_loss: 0.5186 - val_accuracy: 0.7532\n",
            "Epoch 296/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.7500 - val_loss: 0.5186 - val_accuracy: 0.7532\n",
            "Epoch 297/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7652 - val_loss: 0.5185 - val_accuracy: 0.7532\n",
            "Epoch 298/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.7696 - val_loss: 0.5183 - val_accuracy: 0.7532\n",
            "Epoch 299/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7804 - val_loss: 0.5182 - val_accuracy: 0.7532\n",
            "Epoch 300/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.7674 - val_loss: 0.5181 - val_accuracy: 0.7532\n",
            "Epoch 301/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7609 - val_loss: 0.5180 - val_accuracy: 0.7532\n",
            "Epoch 302/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7587 - val_loss: 0.5179 - val_accuracy: 0.7532\n",
            "Epoch 303/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7565 - val_loss: 0.5178 - val_accuracy: 0.7532\n",
            "Epoch 304/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7630 - val_loss: 0.5177 - val_accuracy: 0.7532\n",
            "Epoch 305/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7609 - val_loss: 0.5176 - val_accuracy: 0.7532\n",
            "Epoch 306/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7717 - val_loss: 0.5175 - val_accuracy: 0.7532\n",
            "Epoch 307/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.7652 - val_loss: 0.5173 - val_accuracy: 0.7532\n",
            "Epoch 308/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.7761 - val_loss: 0.5172 - val_accuracy: 0.7532\n",
            "Epoch 309/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7717 - val_loss: 0.5171 - val_accuracy: 0.7532\n",
            "Epoch 310/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.7457 - val_loss: 0.5170 - val_accuracy: 0.7532\n",
            "Epoch 311/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7587 - val_loss: 0.5169 - val_accuracy: 0.7532\n",
            "Epoch 312/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7652 - val_loss: 0.5168 - val_accuracy: 0.7532\n",
            "Epoch 313/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.7804 - val_loss: 0.5166 - val_accuracy: 0.7532\n",
            "Epoch 314/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.7717 - val_loss: 0.5165 - val_accuracy: 0.7532\n",
            "Epoch 315/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.7630 - val_loss: 0.5165 - val_accuracy: 0.7597\n",
            "Epoch 316/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7565 - val_loss: 0.5163 - val_accuracy: 0.7597\n",
            "Epoch 317/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.7565 - val_loss: 0.5163 - val_accuracy: 0.7597\n",
            "Epoch 318/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7652 - val_loss: 0.5162 - val_accuracy: 0.7597\n",
            "Epoch 319/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7587 - val_loss: 0.5162 - val_accuracy: 0.7597\n",
            "Epoch 320/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.7674 - val_loss: 0.5161 - val_accuracy: 0.7597\n",
            "Epoch 321/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7739 - val_loss: 0.5160 - val_accuracy: 0.7597\n",
            "Epoch 322/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7630 - val_loss: 0.5160 - val_accuracy: 0.7597\n",
            "Epoch 323/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7761 - val_loss: 0.5159 - val_accuracy: 0.7597\n",
            "Epoch 324/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7739 - val_loss: 0.5158 - val_accuracy: 0.7597\n",
            "Epoch 325/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7696 - val_loss: 0.5158 - val_accuracy: 0.7597\n",
            "Epoch 326/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7609 - val_loss: 0.5157 - val_accuracy: 0.7597\n",
            "Epoch 327/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7674 - val_loss: 0.5156 - val_accuracy: 0.7597\n",
            "Epoch 328/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7739 - val_loss: 0.5155 - val_accuracy: 0.7597\n",
            "Epoch 329/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7761 - val_loss: 0.5154 - val_accuracy: 0.7597\n",
            "Epoch 330/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.7696 - val_loss: 0.5153 - val_accuracy: 0.7597\n",
            "Epoch 331/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.7761 - val_loss: 0.5153 - val_accuracy: 0.7597\n",
            "Epoch 332/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.7609 - val_loss: 0.5152 - val_accuracy: 0.7597\n",
            "Epoch 333/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7717 - val_loss: 0.5151 - val_accuracy: 0.7597\n",
            "Epoch 334/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7717 - val_loss: 0.5150 - val_accuracy: 0.7597\n",
            "Epoch 335/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7674 - val_loss: 0.5149 - val_accuracy: 0.7597\n",
            "Epoch 336/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7630 - val_loss: 0.5149 - val_accuracy: 0.7532\n",
            "Epoch 337/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7717 - val_loss: 0.5148 - val_accuracy: 0.7532\n",
            "Epoch 338/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7739 - val_loss: 0.5147 - val_accuracy: 0.7532\n",
            "Epoch 339/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.7696 - val_loss: 0.5147 - val_accuracy: 0.7532\n",
            "Epoch 340/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7674 - val_loss: 0.5146 - val_accuracy: 0.7532\n",
            "Epoch 341/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7826 - val_loss: 0.5145 - val_accuracy: 0.7532\n",
            "Epoch 342/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7696 - val_loss: 0.5145 - val_accuracy: 0.7532\n",
            "Epoch 343/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7609 - val_loss: 0.5145 - val_accuracy: 0.7532\n",
            "Epoch 344/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7630 - val_loss: 0.5145 - val_accuracy: 0.7532\n",
            "Epoch 345/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.7674 - val_loss: 0.5144 - val_accuracy: 0.7532\n",
            "Epoch 346/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7761 - val_loss: 0.5143 - val_accuracy: 0.7532\n",
            "Epoch 347/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7739 - val_loss: 0.5142 - val_accuracy: 0.7532\n",
            "Epoch 348/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7870 - val_loss: 0.5142 - val_accuracy: 0.7532\n",
            "Epoch 349/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7652 - val_loss: 0.5142 - val_accuracy: 0.7532\n",
            "Epoch 350/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7587 - val_loss: 0.5141 - val_accuracy: 0.7532\n",
            "Epoch 351/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7804 - val_loss: 0.5141 - val_accuracy: 0.7532\n",
            "Epoch 352/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7478 - val_loss: 0.5140 - val_accuracy: 0.7532\n",
            "Epoch 353/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7674 - val_loss: 0.5140 - val_accuracy: 0.7532\n",
            "Epoch 354/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7717 - val_loss: 0.5140 - val_accuracy: 0.7532\n",
            "Epoch 355/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7587 - val_loss: 0.5140 - val_accuracy: 0.7532\n",
            "Epoch 356/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7717 - val_loss: 0.5140 - val_accuracy: 0.7532\n",
            "Epoch 357/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7717 - val_loss: 0.5138 - val_accuracy: 0.7532\n",
            "Epoch 358/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.7587 - val_loss: 0.5138 - val_accuracy: 0.7532\n",
            "Epoch 359/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7804 - val_loss: 0.5137 - val_accuracy: 0.7532\n",
            "Epoch 360/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7674 - val_loss: 0.5137 - val_accuracy: 0.7532\n",
            "Epoch 361/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7587 - val_loss: 0.5137 - val_accuracy: 0.7532\n",
            "Epoch 362/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7870 - val_loss: 0.5136 - val_accuracy: 0.7532\n",
            "Epoch 363/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7717 - val_loss: 0.5135 - val_accuracy: 0.7532\n",
            "Epoch 364/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7870 - val_loss: 0.5135 - val_accuracy: 0.7532\n",
            "Epoch 365/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.7652 - val_loss: 0.5134 - val_accuracy: 0.7532\n",
            "Epoch 366/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.7652 - val_loss: 0.5134 - val_accuracy: 0.7532\n",
            "Epoch 367/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7652 - val_loss: 0.5133 - val_accuracy: 0.7532\n",
            "Epoch 368/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7652 - val_loss: 0.5133 - val_accuracy: 0.7532\n",
            "Epoch 369/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7500 - val_loss: 0.5132 - val_accuracy: 0.7532\n",
            "Epoch 370/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7696 - val_loss: 0.5132 - val_accuracy: 0.7532\n",
            "Epoch 371/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7739 - val_loss: 0.5131 - val_accuracy: 0.7532\n",
            "Epoch 372/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7522 - val_loss: 0.5132 - val_accuracy: 0.7532\n",
            "Epoch 373/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7630 - val_loss: 0.5131 - val_accuracy: 0.7532\n",
            "Epoch 374/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7848 - val_loss: 0.5131 - val_accuracy: 0.7532\n",
            "Epoch 375/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7609 - val_loss: 0.5130 - val_accuracy: 0.7532\n",
            "Epoch 376/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7696 - val_loss: 0.5131 - val_accuracy: 0.7532\n",
            "Epoch 377/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7783 - val_loss: 0.5130 - val_accuracy: 0.7532\n",
            "Epoch 378/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7935 - val_loss: 0.5130 - val_accuracy: 0.7532\n",
            "Epoch 379/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7696 - val_loss: 0.5129 - val_accuracy: 0.7532\n",
            "Epoch 380/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.7652 - val_loss: 0.5129 - val_accuracy: 0.7532\n",
            "Epoch 381/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7739 - val_loss: 0.5128 - val_accuracy: 0.7532\n",
            "Epoch 382/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7652 - val_loss: 0.5128 - val_accuracy: 0.7532\n",
            "Epoch 383/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7913 - val_loss: 0.5127 - val_accuracy: 0.7532\n",
            "Epoch 384/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7696 - val_loss: 0.5126 - val_accuracy: 0.7532\n",
            "Epoch 385/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7739 - val_loss: 0.5127 - val_accuracy: 0.7468\n",
            "Epoch 386/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7891 - val_loss: 0.5127 - val_accuracy: 0.7532\n",
            "Epoch 387/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7783 - val_loss: 0.5127 - val_accuracy: 0.7468\n",
            "Epoch 388/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7761 - val_loss: 0.5126 - val_accuracy: 0.7532\n",
            "Epoch 389/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7804 - val_loss: 0.5125 - val_accuracy: 0.7532\n",
            "Epoch 390/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7696 - val_loss: 0.5125 - val_accuracy: 0.7597\n",
            "Epoch 391/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7783 - val_loss: 0.5125 - val_accuracy: 0.7597\n",
            "Epoch 392/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7783 - val_loss: 0.5125 - val_accuracy: 0.7597\n",
            "Epoch 393/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7739 - val_loss: 0.5125 - val_accuracy: 0.7597\n",
            "Epoch 394/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7761 - val_loss: 0.5125 - val_accuracy: 0.7597\n",
            "Epoch 395/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7848 - val_loss: 0.5124 - val_accuracy: 0.7597\n",
            "Epoch 396/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7848 - val_loss: 0.5124 - val_accuracy: 0.7597\n",
            "Epoch 397/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7783 - val_loss: 0.5124 - val_accuracy: 0.7597\n",
            "Epoch 398/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7609 - val_loss: 0.5123 - val_accuracy: 0.7597\n",
            "Epoch 399/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7826 - val_loss: 0.5123 - val_accuracy: 0.7597\n",
            "Epoch 400/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7674 - val_loss: 0.5123 - val_accuracy: 0.7597\n",
            "Epoch 401/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7761 - val_loss: 0.5122 - val_accuracy: 0.7597\n",
            "Epoch 402/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7804 - val_loss: 0.5122 - val_accuracy: 0.7597\n",
            "Epoch 403/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7696 - val_loss: 0.5121 - val_accuracy: 0.7597\n",
            "Epoch 404/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7804 - val_loss: 0.5121 - val_accuracy: 0.7597\n",
            "Epoch 405/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7804 - val_loss: 0.5121 - val_accuracy: 0.7597\n",
            "Epoch 406/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7783 - val_loss: 0.5121 - val_accuracy: 0.7597\n",
            "Epoch 407/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7587 - val_loss: 0.5121 - val_accuracy: 0.7597\n",
            "Epoch 408/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.7761 - val_loss: 0.5120 - val_accuracy: 0.7597\n",
            "Epoch 409/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7848 - val_loss: 0.5120 - val_accuracy: 0.7597\n",
            "Epoch 410/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7652 - val_loss: 0.5120 - val_accuracy: 0.7597\n",
            "Epoch 411/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.7717 - val_loss: 0.5120 - val_accuracy: 0.7597\n",
            "Epoch 412/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7717 - val_loss: 0.5120 - val_accuracy: 0.7597\n",
            "Epoch 413/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7609 - val_loss: 0.5120 - val_accuracy: 0.7597\n",
            "Epoch 414/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7826 - val_loss: 0.5119 - val_accuracy: 0.7597\n",
            "Epoch 415/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7804 - val_loss: 0.5119 - val_accuracy: 0.7597\n",
            "Epoch 416/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7804 - val_loss: 0.5119 - val_accuracy: 0.7597\n",
            "Epoch 417/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7761 - val_loss: 0.5118 - val_accuracy: 0.7597\n",
            "Epoch 418/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7609 - val_loss: 0.5118 - val_accuracy: 0.7597\n",
            "Epoch 419/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7696 - val_loss: 0.5118 - val_accuracy: 0.7597\n",
            "Epoch 420/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7826 - val_loss: 0.5117 - val_accuracy: 0.7597\n",
            "Epoch 421/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7674 - val_loss: 0.5117 - val_accuracy: 0.7597\n",
            "Epoch 422/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7739 - val_loss: 0.5117 - val_accuracy: 0.7597\n",
            "Epoch 423/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7783 - val_loss: 0.5117 - val_accuracy: 0.7597\n",
            "Epoch 424/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7804 - val_loss: 0.5117 - val_accuracy: 0.7597\n",
            "Epoch 425/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7739 - val_loss: 0.5117 - val_accuracy: 0.7597\n",
            "Epoch 426/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7761 - val_loss: 0.5117 - val_accuracy: 0.7597\n",
            "Epoch 427/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7826 - val_loss: 0.5117 - val_accuracy: 0.7597\n",
            "Epoch 428/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7717 - val_loss: 0.5116 - val_accuracy: 0.7597\n",
            "Epoch 429/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.7891 - val_loss: 0.5116 - val_accuracy: 0.7597\n",
            "Epoch 430/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7848 - val_loss: 0.5115 - val_accuracy: 0.7597\n",
            "Epoch 431/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7761 - val_loss: 0.5114 - val_accuracy: 0.7597\n",
            "Epoch 432/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7696 - val_loss: 0.5114 - val_accuracy: 0.7597\n",
            "Epoch 433/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7826 - val_loss: 0.5114 - val_accuracy: 0.7597\n",
            "Epoch 434/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7717 - val_loss: 0.5114 - val_accuracy: 0.7597\n",
            "Epoch 435/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7696 - val_loss: 0.5114 - val_accuracy: 0.7597\n",
            "Epoch 436/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7978 - val_loss: 0.5114 - val_accuracy: 0.7597\n",
            "Epoch 437/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7609 - val_loss: 0.5114 - val_accuracy: 0.7597\n",
            "Epoch 438/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7500 - val_loss: 0.5114 - val_accuracy: 0.7597\n",
            "Epoch 439/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7783 - val_loss: 0.5114 - val_accuracy: 0.7597\n",
            "Epoch 440/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7761 - val_loss: 0.5114 - val_accuracy: 0.7597\n",
            "Epoch 441/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7696 - val_loss: 0.5113 - val_accuracy: 0.7597\n",
            "Epoch 442/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7674 - val_loss: 0.5112 - val_accuracy: 0.7597\n",
            "Epoch 443/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7696 - val_loss: 0.5113 - val_accuracy: 0.7597\n",
            "Epoch 444/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7848 - val_loss: 0.5113 - val_accuracy: 0.7597\n",
            "Epoch 445/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7804 - val_loss: 0.5113 - val_accuracy: 0.7597\n",
            "Epoch 446/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7804 - val_loss: 0.5113 - val_accuracy: 0.7597\n",
            "Epoch 447/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7652 - val_loss: 0.5113 - val_accuracy: 0.7597\n",
            "Epoch 448/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7957 - val_loss: 0.5113 - val_accuracy: 0.7597\n",
            "Epoch 449/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7804 - val_loss: 0.5113 - val_accuracy: 0.7597\n",
            "Epoch 450/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7717 - val_loss: 0.5113 - val_accuracy: 0.7597\n",
            "Epoch 451/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7913 - val_loss: 0.5113 - val_accuracy: 0.7597\n",
            "Epoch 452/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.8022 - val_loss: 0.5113 - val_accuracy: 0.7597\n",
            "Epoch 453/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7804 - val_loss: 0.5114 - val_accuracy: 0.7597\n",
            "Epoch 454/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7739 - val_loss: 0.5114 - val_accuracy: 0.7597\n",
            "Epoch 455/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7696 - val_loss: 0.5114 - val_accuracy: 0.7597\n",
            "Epoch 456/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7630 - val_loss: 0.5114 - val_accuracy: 0.7597\n",
            "Epoch 457/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7739 - val_loss: 0.5114 - val_accuracy: 0.7532\n",
            "Epoch 458/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7783 - val_loss: 0.5114 - val_accuracy: 0.7532\n",
            "Epoch 459/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7935 - val_loss: 0.5115 - val_accuracy: 0.7532\n",
            "Epoch 460/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7717 - val_loss: 0.5114 - val_accuracy: 0.7532\n",
            "Epoch 461/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7913 - val_loss: 0.5114 - val_accuracy: 0.7532\n",
            "Epoch 462/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7609 - val_loss: 0.5113 - val_accuracy: 0.7532\n",
            "Epoch 463/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7913 - val_loss: 0.5113 - val_accuracy: 0.7532\n",
            "Epoch 464/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7674 - val_loss: 0.5113 - val_accuracy: 0.7532\n",
            "Epoch 465/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7848 - val_loss: 0.5114 - val_accuracy: 0.7532\n",
            "Epoch 466/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7674 - val_loss: 0.5114 - val_accuracy: 0.7532\n",
            "Epoch 467/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7913 - val_loss: 0.5113 - val_accuracy: 0.7532\n",
            "Epoch 468/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7870 - val_loss: 0.5113 - val_accuracy: 0.7532\n",
            "Epoch 469/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7696 - val_loss: 0.5113 - val_accuracy: 0.7532\n",
            "Epoch 470/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7739 - val_loss: 0.5113 - val_accuracy: 0.7532\n",
            "Epoch 471/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7717 - val_loss: 0.5113 - val_accuracy: 0.7532\n",
            "Epoch 472/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7630 - val_loss: 0.5113 - val_accuracy: 0.7532\n",
            "Epoch 473/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7848 - val_loss: 0.5113 - val_accuracy: 0.7532\n",
            "Epoch 474/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.7913 - val_loss: 0.5113 - val_accuracy: 0.7532\n",
            "Epoch 475/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7739 - val_loss: 0.5112 - val_accuracy: 0.7532\n",
            "Epoch 476/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7891 - val_loss: 0.5112 - val_accuracy: 0.7532\n",
            "Epoch 477/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7783 - val_loss: 0.5113 - val_accuracy: 0.7532\n",
            "Epoch 478/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7717 - val_loss: 0.5113 - val_accuracy: 0.7532\n",
            "Epoch 479/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7761 - val_loss: 0.5112 - val_accuracy: 0.7532\n",
            "Epoch 480/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7783 - val_loss: 0.5113 - val_accuracy: 0.7532\n",
            "Epoch 481/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7891 - val_loss: 0.5113 - val_accuracy: 0.7532\n",
            "Epoch 482/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7891 - val_loss: 0.5112 - val_accuracy: 0.7532\n",
            "Epoch 483/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7696 - val_loss: 0.5113 - val_accuracy: 0.7532\n",
            "Epoch 484/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7717 - val_loss: 0.5113 - val_accuracy: 0.7532\n",
            "Epoch 485/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7696 - val_loss: 0.5113 - val_accuracy: 0.7532\n",
            "Epoch 486/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7935 - val_loss: 0.5113 - val_accuracy: 0.7532\n",
            "Epoch 487/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7870 - val_loss: 0.5113 - val_accuracy: 0.7532\n",
            "Epoch 488/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7717 - val_loss: 0.5113 - val_accuracy: 0.7532\n",
            "Epoch 489/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7674 - val_loss: 0.5113 - val_accuracy: 0.7532\n",
            "Epoch 490/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7783 - val_loss: 0.5114 - val_accuracy: 0.7532\n",
            "Epoch 491/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7826 - val_loss: 0.5114 - val_accuracy: 0.7532\n",
            "Epoch 492/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7848 - val_loss: 0.5114 - val_accuracy: 0.7532\n",
            "Epoch 493/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7783 - val_loss: 0.5114 - val_accuracy: 0.7532\n",
            "Epoch 494/500\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7630 - val_loss: 0.5114 - val_accuracy: 0.7532\n",
            "Epoch 495/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7804 - val_loss: 0.5114 - val_accuracy: 0.7532\n",
            "Epoch 496/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7826 - val_loss: 0.5114 - val_accuracy: 0.7532\n",
            "Epoch 497/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7696 - val_loss: 0.5114 - val_accuracy: 0.7532\n",
            "Epoch 498/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.7913 - val_loss: 0.5115 - val_accuracy: 0.7532\n",
            "Epoch 499/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7761 - val_loss: 0.5115 - val_accuracy: 0.7532\n",
            "Epoch 500/500\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.8022 - val_loss: 0.5114 - val_accuracy: 0.7532\n"
          ]
        }
      ],
      "source": [
        "history_1 = model_1.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=500, batch_size=8, verbose = 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIjqo-qAedxY"
      },
      "source": [
        "Evaluating the Model on the Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fORyflJMdpzz",
        "outputId": "7368d544-f0e8-4608-eb82-c6a5315e6561"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7662\n",
            "accuracy: 76.62%\n"
          ]
        }
      ],
      "source": [
        "scores_1 = model_1.evaluate(X_test, y_test)\n",
        "print(\"%s: %.2f%%\" % (model_1.metrics_names[1], scores_1[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMmNbnPPfJaZ"
      },
      "source": [
        "Plotting Training Accuracy VS Validation Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "nwNGkLgvei5z",
        "outputId": "18a4a5a2-8ebb-4723-fb76-2fbebea5189a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQseBN10fMnR"
      },
      "source": [
        "Plotting Training Loss VS Validation Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "Jj4LByV3epcY",
        "outputId": "3adb7583-2750-4ecd-ff4a-4314c310aadf"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ML_PROJECT_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
